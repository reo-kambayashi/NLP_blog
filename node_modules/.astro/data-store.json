[["Map",1,2,9,10],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.9.0","content-config-digest","6ab83d4c224a4955","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"compressHTML\":true,\"base\":\"/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[],\"experimentalDefaultStyles\":true},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":{\"type\":\"shiki\",\"excludeLangs\":[\"math\"]},\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[null],\"rehypePlugins\":[null],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"responsiveImages\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false,\"csp\":false},\"legacy\":{\"collections\":false}}","papers",["Map",11,12,76,77,121,122,166,167,200,201,240,241,279,280],"large-language-models-are-human-level-prompt-engineers2023",{"id":11,"data":13,"body":16,"filePath":17,"digest":18,"rendered":19,"legacyId":75},{"title":14,"date":15},"Large Language Models Are Human-Level Prompt Engineers (2023)","2025-06-06","## 著者\n[Yongchao Zhou](https://arxiv.org/search/cs?searchtype=author&query=Zhou,+Y), [Andrei Ioan Muresanu](https://arxiv.org/search/cs?searchtype=author&query=Muresanu,+A+I), [Ziwen Han](https://arxiv.org/search/cs?searchtype=author&query=Han,+Z), [Keiran Paster](https://arxiv.org/search/cs?searchtype=author&query=Paster,+K), [Silviu Pitis](https://arxiv.org/search/cs?searchtype=author&query=Pitis,+S), [Harris Chan](https://arxiv.org/search/cs?searchtype=author&query=Chan,+H), [Jimmy Ba](https://arxiv.org/search/cs?searchtype=author&query=Ba,+J)\n\n## arXivリンク\nhttps://arxiv.org/abs/2211.01910\n\n## 要約\n- プロンプトエンジニアリングを自動化する「Automatic Prompt Engineer (APE)」を提案\n-  ざっくり**LLMにLLMのプロンプトを考えさせる**手法。\n- APEは人間が時間をかけて考えたものと同等かそれ以上の性能を達成\n-  APEのステップ\n\t- LLMに「こういう入力をしたらこういう出力をする」という例を見せて、指示文の候補をいっぱい作らせる\n\t- 候補を試し、その結果をスコアリング\n\t- 最も高いスコアの指示を最良のプロンプトとする\n\n## Abstract\n- LLMは汎用的でいいけど「人間が望むことをさせる」のって難しいよね\n\t- →プロンプト大事\n- 幅広いプロンプトを試す必要があるけどどの指示がどのモデルでいいのかわからない\n- LLMを自然言語でプログラムが指定されるブラックボックスなコンピュータとみなそう\n### 提案手法(APE)\nゼロショット学習において24件中24件のInstruction Inductionタスクと21件中17件のBig-Benchタスクで人間レベルの性能を達成\n\n## APEのアルゴリズム(お気持ちベース)\n### \"提案→評価とフィルタリング→選択\"のサイクルを自動化\n### 指示候補の提案\n- LLMにタスクの入出力例を見せ、タスクの遂行用指示文をいっぱい考えさせる。\n- 順方向生成\n\t- 例を先に提示し、最後にこういう指示でしたと続ける\n- 逆方向生成\n\t- \u003Cここに指示を挿入>的な感じで穴埋め問題にして、その後に例を提示\n### 評価・フィルタリング\n指示候補を使って、実際に別のLLMにタスクを解かせ、その性能をスコア付け\n#### 評価基準\n- **実行精度 (Execution accuracy)**: 指示通りにタスクを実行した結果が、想定される正解と一致したかどうかで評価\n- **対数尤度 (Log probability)**: どれだけ正解に近い答えを生成できそうかを確率で評価\n#### フィルタリング\n- 少数の訓練データで候補を評価\n- スコアが良かった上位数パーを残して破棄\n- 残ったものを別の訓練データで再評価\n- これを繰り返して少数の交互に絞る\n#### 選択\n- フィルタリングで残った候補から最も高いスコアのものを採用\n\n## APEを使った結果\n-  ゼロショットで24個のInstruction Inductionタスク全てにおいて、人間が作成したプロンプトと同等かそれ以上の性能を達成\n-  フューショットで24タスク中21タスクで性能が向上するか、同等の結果\n- 高難易度タスク(BIG-Bench)でも17/21で同等かそれ以上\n## いい感じの発見\n### Zero-shot Chain-of-Thought\n- \"Let's think step by step.\"をAPEが改善\n\t- \"Let's work this out in a step by step way to be sure we have the right answer\"のほうがいいらしい\n### TruthfulQA\n- APEがLLMの応答スタイルを制御して「真実性」と「情報提供性」のトレードオフを発見\n\t- 真実性をあげるために嘘をつかせないプロンプト(you have no comment→回答を拒否する選択肢をあたえる)をAPEが見つけた\n\n## 結論\n人間による入力を最小限にしつつ、最適なプロンプトをみつける方法としてAPEは有用\n\n## 感想\n- プロンプト集みたいなのがよくネットに転がってるけどこういうのでちゃんと性能が確認されているのか気になった。\n- 人間が直感的にわかりやすいプロンプトと、LLMがいい性能を示すプロンプトがちょっとちがっておもろい\n- モデル間でも最適なプロンプトがちがって、InstractGPTで最適なプロンプトをGPT-3で用いるとスコアが下がることがあるらしい←自分が使ってるモデルで最適なのを調べる必要あり\n- ↑モデルごと違うならそれこそ自動化とかしないと見つけるの大変そう","src/content/papers/Large Language Models Are Human-Level Prompt Engineers(2023).md","75a5091659b958d9",{"html":20,"metadata":21},"\u003Ch2 id=\"著者\">著者\u003C/h2>\n\u003Cp>\u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Zhou,+Y\">Yongchao Zhou\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Muresanu,+A+I\">Andrei Ioan Muresanu\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Han,+Z\">Ziwen Han\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Paster,+K\">Keiran Paster\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Pitis,+S\">Silviu Pitis\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Chan,+H\">Harris Chan\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Ba,+J\">Jimmy Ba\u003C/a>\u003C/p>\n\u003Ch2 id=\"arxivリンク\">arXivリンク\u003C/h2>\n\u003Cp>\u003Ca href=\"https://arxiv.org/abs/2211.01910\">https://arxiv.org/abs/2211.01910\u003C/a>\u003C/p>\n\u003Ch2 id=\"要約\">要約\u003C/h2>\n\u003Cul>\n\u003Cli>プロンプトエンジニアリングを自動化する「Automatic Prompt Engineer (APE)」を提案\u003C/li>\n\u003Cli>ざっくり\u003Cstrong>LLMにLLMのプロンプトを考えさせる\u003C/strong>手法。\u003C/li>\n\u003Cli>APEは人間が時間をかけて考えたものと同等かそれ以上の性能を達成\u003C/li>\n\u003Cli>APEのステップ\n\u003Cul>\n\u003Cli>LLMに「こういう入力をしたらこういう出力をする」という例を見せて、指示文の候補をいっぱい作らせる\u003C/li>\n\u003Cli>候補を試し、その結果をスコアリング\u003C/li>\n\u003Cli>最も高いスコアの指示を最良のプロンプトとする\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"abstract\">Abstract\u003C/h2>\n\u003Cul>\n\u003Cli>LLMは汎用的でいいけど「人間が望むことをさせる」のって難しいよね\n\u003Cul>\n\u003Cli>→プロンプト大事\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>幅広いプロンプトを試す必要があるけどどの指示がどのモデルでいいのかわからない\u003C/li>\n\u003Cli>LLMを自然言語でプログラムが指定されるブラックボックスなコンピュータとみなそう\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"提案手法ape\">提案手法(APE)\u003C/h3>\n\u003Cp>ゼロショット学習において24件中24件のInstruction Inductionタスクと21件中17件のBig-Benchタスクで人間レベルの性能を達成\u003C/p>\n\u003Ch2 id=\"apeのアルゴリズムお気持ちベース\">APEのアルゴリズム(お気持ちベース)\u003C/h2>\n\u003Ch3 id=\"提案評価とフィルタリング選択のサイクルを自動化\">“提案→評価とフィルタリング→選択”のサイクルを自動化\u003C/h3>\n\u003Ch3 id=\"指示候補の提案\">指示候補の提案\u003C/h3>\n\u003Cul>\n\u003Cli>LLMにタスクの入出力例を見せ、タスクの遂行用指示文をいっぱい考えさせる。\u003C/li>\n\u003Cli>順方向生成\n\u003Cul>\n\u003Cli>例を先に提示し、最後にこういう指示でしたと続ける\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>逆方向生成\n\u003Cul>\n\u003Cli>&#x3C;ここに指示を挿入>的な感じで穴埋め問題にして、その後に例を提示\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"評価フィルタリング\">評価・フィルタリング\u003C/h3>\n\u003Cp>指示候補を使って、実際に別のLLMにタスクを解かせ、その性能をスコア付け\u003C/p>\n\u003Ch4 id=\"評価基準\">評価基準\u003C/h4>\n\u003Cul>\n\u003Cli>\u003Cstrong>実行精度 (Execution accuracy)\u003C/strong>: 指示通りにタスクを実行した結果が、想定される正解と一致したかどうかで評価\u003C/li>\n\u003Cli>\u003Cstrong>対数尤度 (Log probability)\u003C/strong>: どれだけ正解に近い答えを生成できそうかを確率で評価\u003C/li>\n\u003C/ul>\n\u003Ch4 id=\"フィルタリング\">フィルタリング\u003C/h4>\n\u003Cul>\n\u003Cli>少数の訓練データで候補を評価\u003C/li>\n\u003Cli>スコアが良かった上位数パーを残して破棄\u003C/li>\n\u003Cli>残ったものを別の訓練データで再評価\u003C/li>\n\u003Cli>これを繰り返して少数の交互に絞る\u003C/li>\n\u003C/ul>\n\u003Ch4 id=\"選択\">選択\u003C/h4>\n\u003Cul>\n\u003Cli>フィルタリングで残った候補から最も高いスコアのものを採用\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"apeを使った結果\">APEを使った結果\u003C/h2>\n\u003Cul>\n\u003Cli>ゼロショットで24個のInstruction Inductionタスク全てにおいて、人間が作成したプロンプトと同等かそれ以上の性能を達成\u003C/li>\n\u003Cli>フューショットで24タスク中21タスクで性能が向上するか、同等の結果\u003C/li>\n\u003Cli>高難易度タスク(BIG-Bench)でも17/21で同等かそれ以上\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"いい感じの発見\">いい感じの発見\u003C/h2>\n\u003Ch3 id=\"zero-shot-chain-of-thought\">Zero-shot Chain-of-Thought\u003C/h3>\n\u003Cul>\n\u003Cli>“Let’s think step by step.”をAPEが改善\n\u003Cul>\n\u003Cli>“Let’s work this out in a step by step way to be sure we have the right answer”のほうがいいらしい\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"truthfulqa\">TruthfulQA\u003C/h3>\n\u003Cul>\n\u003Cli>APEがLLMの応答スタイルを制御して「真実性」と「情報提供性」のトレードオフを発見\n\u003Cul>\n\u003Cli>真実性をあげるために嘘をつかせないプロンプト(you have no comment→回答を拒否する選択肢をあたえる)をAPEが見つけた\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"結論\">結論\u003C/h2>\n\u003Cp>人間による入力を最小限にしつつ、最適なプロンプトをみつける方法としてAPEは有用\u003C/p>\n\u003Ch2 id=\"感想\">感想\u003C/h2>\n\u003Cul>\n\u003Cli>プロンプト集みたいなのがよくネットに転がってるけどこういうのでちゃんと性能が確認されているのか気になった。\u003C/li>\n\u003Cli>人間が直感的にわかりやすいプロンプトと、LLMがいい性能を示すプロンプトがちょっとちがっておもろい\u003C/li>\n\u003Cli>モデル間でも最適なプロンプトがちがって、InstractGPTで最適なプロンプトをGPT-3で用いるとスコアが下がることがあるらしい←自分が使ってるモデルで最適なのを調べる必要あり\u003C/li>\n\u003Cli>↑モデルごと違うならそれこそ自動化とかしないと見つけるの大変そう\u003C/li>\n\u003C/ul>",{"headings":22,"localImagePaths":71,"remoteImagePaths":72,"frontmatter":73,"imagePaths":74},[23,26,29,31,34,38,41,44,46,49,52,54,56,59,61,64,67,69],{"depth":24,"slug":25,"text":25},2,"著者",{"depth":24,"slug":27,"text":28},"arxivリンク","arXivリンク",{"depth":24,"slug":30,"text":30},"要約",{"depth":24,"slug":32,"text":33},"abstract","Abstract",{"depth":35,"slug":36,"text":37},3,"提案手法ape","提案手法(APE)",{"depth":24,"slug":39,"text":40},"apeのアルゴリズムお気持ちベース","APEのアルゴリズム(お気持ちベース)",{"depth":35,"slug":42,"text":43},"提案評価とフィルタリング選択のサイクルを自動化","“提案→評価とフィルタリング→選択”のサイクルを自動化",{"depth":35,"slug":45,"text":45},"指示候補の提案",{"depth":35,"slug":47,"text":48},"評価フィルタリング","評価・フィルタリング",{"depth":50,"slug":51,"text":51},4,"評価基準",{"depth":50,"slug":53,"text":53},"フィルタリング",{"depth":50,"slug":55,"text":55},"選択",{"depth":24,"slug":57,"text":58},"apeを使った結果","APEを使った結果",{"depth":24,"slug":60,"text":60},"いい感じの発見",{"depth":35,"slug":62,"text":63},"zero-shot-chain-of-thought","Zero-shot Chain-of-Thought",{"depth":35,"slug":65,"text":66},"truthfulqa","TruthfulQA",{"depth":24,"slug":68,"text":68},"結論",{"depth":24,"slug":70,"text":70},"感想",[],[],{"title":14,"date":15},[],"Large Language Models Are Human-Level Prompt Engineers(2023).md","the-llama-3-herd-of-models2024",{"id":76,"data":78,"body":81,"filePath":82,"digest":83,"rendered":84,"legacyId":120},{"title":79,"date":80},"The Llama 3 Herd of Models (2024)","2025-06-07","## arXiv\nhttps://arxiv.org/abs/2407.21783\n\n## 要約\n- Llama-3に関する研究開発\n- 15.6Tトークンで学習された8B,70B,405Bのdense Transformer\n- 128Kトークンのコンテクストウィンドウ\n- **DPO！！！**\n- 4oとかClaude3.5とかに匹敵するレベル\n- Llama-2 70BとLlama-3 8Bが同じぐらいの性能\n\n## 学習方法\n1. 教師なし学習により、大量のテキストコーパスから学習\n2. 現在のモデルでプリファレンスデータ（出力を人手で比較評価したやつ）を作成し、報酬モデリングを実施\n3. 現在のモデル＋報酬モデルSFT用のデータを作成し、ベースモデルをチューニング\n4. プリファレンスデータをLLMにマッチさせるようにDPOでベストモデルを更新\n\n## 開発における3つの主要要素\n### データ\n- 事前、事後両方の学習でのデータの質と量が向上\n- データミックスは、一般知識50％、数学的推論25％、コード17％、多言語トークン8％\n- 安全性のためのデータフィルタリング\n### スケール\n- Llama 2の最大verより約50倍の計算量でモデルを訓練\n### 複雑性の管理\n- 標準のdense Transformerのアーキテクチャを採用\n- MoEは複雑だから避けて安定性重視\n\t- MoEってなんですかの人はこちら\n\t- https://www.ibm.com/jp-ja/think/topics/mixture-of-experts\n\n## Llama 2からの変更点\n### PPO → DPO\n- ここで出てきますねDPO\n### データ量\n- 1.8兆tokens → 15兆tokens\n### モデルアーキテクチャの微変更\n- Grouped Query Attention(GQA)の採用\n\t- GQAのGemini解説: https://g.co/gemini/share/5a3c1c47f73d\n\t- 推論速度向上\n\t- デコード中のキャッシュサイズ削減\n- トークンボキャブラリの拡張\n\t- tiktokenトークナイザの100K+非英語言語用の28Kトークン\n\t- 英語データの圧縮率が3.17文字/token から3.94文字/token に向上\n\t\t- 同じ計算量でいっぱい読める\n\t- RoPEベースの周波数ハイパラが増加\n\t\t- RoPEは位置情報を位置の加算じゃなくて回転するやつ\n\t\t- 500,000に増加(何が嬉しいのかよくわからなかった)\n\n## 感想\n- もうDPOしか頭に入ってこなかった\n- RoPEのところの話があんまり理解できなかった\n- やっぱりLlamaは安全性にすごい気を使っていそう\n\n## 著者(多すぎ)\n[Aaron Grattafiori](https://arxiv.org/search/cs?searchtype=author&query=Grattafiori,+A), [Abhimanyu Dubey](https://arxiv.org/search/cs?searchtype=author&query=Dubey,+A), [Abhinav Jauhri](https://arxiv.org/search/cs?searchtype=author&query=Jauhri,+A), [Abhinav Pandey](https://arxiv.org/search/cs?searchtype=author&query=Pandey,+A), [Abhishek Kadian](https://arxiv.org/search/cs?searchtype=author&query=Kadian,+A), [Ahmad Al-Dahle](https://arxiv.org/search/cs?searchtype=author&query=Al-Dahle,+A), [Aiesha Letman](https://arxiv.org/search/cs?searchtype=author&query=Letman,+A), [Akhil Mathur](https://arxiv.org/search/cs?searchtype=author&query=Mathur,+A), [Alan Schelten](https://arxiv.org/search/cs?searchtype=author&query=Schelten,+A), [Alex Vaughan](https://arxiv.org/search/cs?searchtype=author&query=Vaughan,+A), [Amy Yang](https://arxiv.org/search/cs?searchtype=author&query=Yang,+A), [Angela Fan](https://arxiv.org/search/cs?searchtype=author&query=Fan,+A), [Anirudh Goyal](https://arxiv.org/search/cs?searchtype=author&query=Goyal,+A), [Anthony Hartshorn](https://arxiv.org/search/cs?searchtype=author&query=Hartshorn,+A), [Aobo Yang](https://arxiv.org/search/cs?searchtype=author&query=Yang,+A), [Archi Mitra](https://arxiv.org/search/cs?searchtype=author&query=Mitra,+A), [Archie Sravankumar](https://arxiv.org/search/cs?searchtype=author&query=Archie), [Artem Korenev](https://arxiv.org/search/cs?searchtype=author&query=Korenev,+A), [Arthur Hinsvark](https://arxiv.org/search/cs?searchtype=author&query=Hinsvark,+A), [Arun Rao](https://arxiv.org/search/cs?searchtype=author&query=Rao,+A), [Aston Zhang](https://arxiv.org/search/cs?searchtype=author&query=Zhang,+A), [Aurelien Rodriguez](https://arxiv.org/search/cs?searchtype=author&query=Rodriguez,+A), [Austen Gregerson](https://arxiv.org/search/cs?searchtype=author&query=Gregerson,+A), [Ava Spataru](https://arxiv.org/search/cs?searchtype=author&query=Spataru,+A), [Baptiste Roziere](https://arxiv.org/search/cs?searchtype=author&query=Roziere,+B), [Bethany Biron](https://arxiv.org/search/cs?searchtype=author&query=Biron,+B), [Binh Tang](https://arxiv.org/search/cs?searchtype=author&query=Tang,+B), [Bobbie Chern](https://arxiv.org/search/cs?searchtype=author&query=Chern,+B), [Charlotte Caucheteux](https://arxiv.org/search/cs?searchtype=author&query=Caucheteux,+C), [Chaya Nayak](https://arxiv.org/search/cs?searchtype=author&query=Nayak,+C), [Chloe Bi](https://arxiv.org/search/cs?searchtype=author&query=Bi,+C), [Chris Marra](https://arxiv.org/search/cs?searchtype=author&query=Marra,+C), [Chris McConnell](https://arxiv.org/search/cs?searchtype=author&query=McConnell,+C), [Christian Keller](https://arxiv.org/search/cs?searchtype=author&query=Keller,+C), [Christophe Touret](https://arxiv.org/search/cs?searchtype=author&query=Touret,+C), [Chunyang Wu](https://arxiv.org/search/cs?searchtype=author&query=Wu,+C), [Corinne Wong](https://arxiv.org/search/cs?searchtype=author&query=Wong,+C), [Cristian Canton Ferrer](https://arxiv.org/search/cs?searchtype=author&query=Ferrer,+C+C), [Cyrus Nikolaidis](https://arxiv.org/search/cs?searchtype=author&query=Nikolaidis,+C), [Damien Allonsius](https://arxiv.org/search/cs?searchtype=author&query=Allonsius,+D), [Daniel Song](https://arxiv.org/search/cs?searchtype=author&query=Song,+D), [Danielle Pintz](https://arxiv.org/search/cs?searchtype=author&query=Pintz,+D), [Danny Livshits](https://arxiv.org/search/cs?searchtype=author&query=Livshits,+D), [Danny Wyatt](https://arxiv.org/search/cs?searchtype=author&query=Wyatt,+D), [David Esiobu](https://arxiv.org/search/cs?searchtype=author&query=Esiobu,+D), [Dhruv Choudhary](https://arxiv.org/search/cs?searchtype=author&query=Choudhary,+D), [Dhruv Mahajan](https://arxiv.org/search/cs?searchtype=author&query=Mahajan,+D), [Diego Garcia-Olano](https://arxiv.org/search/cs?searchtype=author&query=Garcia-Olano,+D), [Diego Perino](https://arxiv.org/search/cs?searchtype=author&query=Perino,+D), [Dieuwke Hupkes](https://arxiv.org/search/cs?searchtype=author&query=Hupkes,+D), [Egor Lakomkin](https://arxiv.org/search/cs?searchtype=author&query=Lakomkin,+E), [Ehab AlBadawy](https://arxiv.org/search/cs?searchtype=author&query=AlBadawy,+E), [Elina Lobanova](https://arxiv.org/search/cs?searchtype=author&query=Lobanova,+E), [Emily Dinan](https://arxiv.org/search/cs?searchtype=author&query=Dinan,+E), [Eric Michael Smith](https://arxiv.org/search/cs?searchtype=author&query=Smith,+E+M), [Filip Radenovic](https://arxiv.org/search/cs?searchtype=author&query=Radenovic,+F), [Francisco Guzmán](https://arxiv.org/search/cs?searchtype=author&query=Guzm%C3%A1n,+F), [Frank Zhang](https://arxiv.org/search/cs?searchtype=author&query=Zhang,+F), [Gabriel Synnaeve](https://arxiv.org/search/cs?searchtype=author&query=Synnaeve,+G), [Gabrielle Lee](https://arxiv.org/search/cs?searchtype=author&query=Lee,+G), [Georgia Lewis Anderson](https://arxiv.org/search/cs?searchtype=author&query=Anderson,+G+L), [Govind Thattai](https://arxiv.org/search/cs?searchtype=author&query=Thattai,+G), [Graeme Nail](https://arxiv.org/search/cs?searchtype=author&query=Nail,+G), [Gregoire Mialon](https://arxiv.org/search/cs?searchtype=author&query=Mialon,+G), [Guan Pang](https://arxiv.org/search/cs?searchtype=author&query=Pang,+G), [Guillem Cucurell](https://arxiv.org/search/cs?searchtype=author&query=Cucurell,+G), [Hailey Nguyen](https://arxiv.org/search/cs?searchtype=author&query=Nguyen,+H), [Hannah Korevaar](https://arxiv.org/search/cs?searchtype=author&query=Korevaar,+H), [Hu Xu](https://arxiv.org/search/cs?searchtype=author&query=Xu,+H), [Hugo Touvron](https://arxiv.org/search/cs?searchtype=author&query=Touvron,+H), [Iliyan Zarov](https://arxiv.org/search/cs?searchtype=author&query=Zarov,+I), [Imanol Arrieta Ibarra](https://arxiv.org/search/cs?searchtype=author&query=Ibarra,+I+A), [Isabel Kloumann](https://arxiv.org/search/cs?searchtype=author&query=Kloumann,+I), [Ishan Misra](https://arxiv.org/search/cs?searchtype=author&query=Misra,+I), [Ivan Evtimov](https://arxiv.org/search/cs?searchtype=author&query=Evtimov,+I), [Jack Zhang](https://arxiv.org/search/cs?searchtype=author&query=Zhang,+J), [Jade Copet](https://arxiv.org/search/cs?searchtype=author&query=Copet,+J), [Jaewon Lee](https://arxiv.org/search/cs?searchtype=author&query=Lee,+J), [Jan Geffert](https://arxiv.org/search/cs?searchtype=author&query=Geffert,+J), [Jana Vranes](https://arxiv.org/search/cs?searchtype=author&query=Vranes,+J), [Jason Park](https://arxiv.org/search/cs?searchtype=author&query=Park,+J), [Jay Mahadeokar](https://arxiv.org/search/cs?searchtype=author&query=Mahadeokar,+J), [Jeet Shah](https://arxiv.org/search/cs?searchtype=author&query=Shah,+J), [Jelmer van der Linde](https://arxiv.org/search/cs?searchtype=author&query=van+der+Linde,+J), [Jennifer Billock](https://arxiv.org/search/cs?searchtype=author&query=Billock,+J), [Jenny Hong](https://arxiv.org/search/cs?searchtype=author&query=Hong,+J), [Jenya Lee](https://arxiv.org/search/cs?searchtype=author&query=Lee,+J), [Jeremy Fu](https://arxiv.org/search/cs?searchtype=author&query=Fu,+J), [Jianfeng Chi](https://arxiv.org/search/cs?searchtype=author&query=Chi,+J), [Jianyu Huang](https://arxiv.org/search/cs?searchtype=author&query=Huang,+J), [Jiawen Liu](https://arxiv.org/search/cs?searchtype=author&query=Liu,+J), [Jie Wang](https://arxiv.org/search/cs?searchtype=author&query=Wang,+J), [Jiecao Yu](https://arxiv.org/search/cs?searchtype=author&query=Yu,+J), [Joanna Bitton](https://arxiv.org/search/cs?searchtype=author&query=Bitton,+J), [Joe Spisak](https://arxiv.org/search/cs?searchtype=author&query=Spisak,+J), [Jongsoo Park](https://arxiv.org/search/cs?searchtype=author&query=Park,+J), [Joseph Rocca](https://arxiv.org/search/cs?searchtype=author&query=Rocca,+J), [Joshua Johnstun](https://arxiv.org/search/cs?searchtype=author&query=Johnstun,+J), [Joshua Saxe](https://arxiv.org/search/cs?searchtype=author&query=Saxe,+J), [Junteng Jia](https://arxiv.org/search/cs?searchtype=author&query=Jia,+J) et al. (460 additional authors not shown)","src/content/papers/The Llama 3 Herd of Models(2024).md","755a3621c0e24361",{"html":85,"metadata":86},"\u003Ch2 id=\"arxiv\">arXiv\u003C/h2>\n\u003Cp>\u003Ca href=\"https://arxiv.org/abs/2407.21783\">https://arxiv.org/abs/2407.21783\u003C/a>\u003C/p>\n\u003Ch2 id=\"要約\">要約\u003C/h2>\n\u003Cul>\n\u003Cli>Llama-3に関する研究開発\u003C/li>\n\u003Cli>15.6Tトークンで学習された8B,70B,405Bのdense Transformer\u003C/li>\n\u003Cli>128Kトークンのコンテクストウィンドウ\u003C/li>\n\u003Cli>\u003Cstrong>DPO！！！\u003C/strong>\u003C/li>\n\u003Cli>4oとかClaude3.5とかに匹敵するレベル\u003C/li>\n\u003Cli>Llama-2 70BとLlama-3 8Bが同じぐらいの性能\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"学習方法\">学習方法\u003C/h2>\n\u003Col>\n\u003Cli>教師なし学習により、大量のテキストコーパスから学習\u003C/li>\n\u003Cli>現在のモデルでプリファレンスデータ（出力を人手で比較評価したやつ）を作成し、報酬モデリングを実施\u003C/li>\n\u003Cli>現在のモデル＋報酬モデルSFT用のデータを作成し、ベースモデルをチューニング\u003C/li>\n\u003Cli>プリファレンスデータをLLMにマッチさせるようにDPOでベストモデルを更新\u003C/li>\n\u003C/ol>\n\u003Ch2 id=\"開発における3つの主要要素\">開発における3つの主要要素\u003C/h2>\n\u003Ch3 id=\"データ\">データ\u003C/h3>\n\u003Cul>\n\u003Cli>事前、事後両方の学習でのデータの質と量が向上\u003C/li>\n\u003Cli>データミックスは、一般知識50％、数学的推論25％、コード17％、多言語トークン8％\u003C/li>\n\u003Cli>安全性のためのデータフィルタリング\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"スケール\">スケール\u003C/h3>\n\u003Cul>\n\u003Cli>Llama 2の最大verより約50倍の計算量でモデルを訓練\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"複雑性の管理\">複雑性の管理\u003C/h3>\n\u003Cul>\n\u003Cli>標準のdense Transformerのアーキテクチャを採用\u003C/li>\n\u003Cli>MoEは複雑だから避けて安定性重視\n\u003Cul>\n\u003Cli>MoEってなんですかの人はこちら\u003C/li>\n\u003Cli>\u003Ca href=\"https://www.ibm.com/jp-ja/think/topics/mixture-of-experts\">https://www.ibm.com/jp-ja/think/topics/mixture-of-experts\u003C/a>\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"llama-2からの変更点\">Llama 2からの変更点\u003C/h2>\n\u003Ch3 id=\"ppo--dpo\">PPO → DPO\u003C/h3>\n\u003Cul>\n\u003Cli>ここで出てきますねDPO\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"データ量\">データ量\u003C/h3>\n\u003Cul>\n\u003Cli>1.8兆tokens → 15兆tokens\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"モデルアーキテクチャの微変更\">モデルアーキテクチャの微変更\u003C/h3>\n\u003Cul>\n\u003Cli>Grouped Query Attention(GQA)の採用\n\u003Cul>\n\u003Cli>GQAのGemini解説: \u003Ca href=\"https://g.co/gemini/share/5a3c1c47f73d\">https://g.co/gemini/share/5a3c1c47f73d\u003C/a>\u003C/li>\n\u003Cli>推論速度向上\u003C/li>\n\u003Cli>デコード中のキャッシュサイズ削減\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>トークンボキャブラリの拡張\n\u003Cul>\n\u003Cli>tiktokenトークナイザの100K+非英語言語用の28Kトークン\u003C/li>\n\u003Cli>英語データの圧縮率が3.17文字/token から3.94文字/token に向上\n\u003Cul>\n\u003Cli>同じ計算量でいっぱい読める\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>RoPEベースの周波数ハイパラが増加\n\u003Cul>\n\u003Cli>RoPEは位置情報を位置の加算じゃなくて回転するやつ\u003C/li>\n\u003Cli>500,000に増加(何が嬉しいのかよくわからなかった)\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"感想\">感想\u003C/h2>\n\u003Cul>\n\u003Cli>もうDPOしか頭に入ってこなかった\u003C/li>\n\u003Cli>RoPEのところの話があんまり理解できなかった\u003C/li>\n\u003Cli>やっぱりLlamaは安全性にすごい気を使っていそう\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"著者多すぎ\">著者(多すぎ)\u003C/h2>\n\u003Cp>\u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Grattafiori,+A\">Aaron Grattafiori\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Dubey,+A\">Abhimanyu Dubey\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Jauhri,+A\">Abhinav Jauhri\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Pandey,+A\">Abhinav Pandey\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Kadian,+A\">Abhishek Kadian\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Al-Dahle,+A\">Ahmad Al-Dahle\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Letman,+A\">Aiesha Letman\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Mathur,+A\">Akhil Mathur\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Schelten,+A\">Alan Schelten\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Vaughan,+A\">Alex Vaughan\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Yang,+A\">Amy Yang\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Fan,+A\">Angela Fan\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Goyal,+A\">Anirudh Goyal\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Hartshorn,+A\">Anthony Hartshorn\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Yang,+A\">Aobo Yang\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Mitra,+A\">Archi Mitra\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Archie\">Archie Sravankumar\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Korenev,+A\">Artem Korenev\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Hinsvark,+A\">Arthur Hinsvark\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Rao,+A\">Arun Rao\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Zhang,+A\">Aston Zhang\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Rodriguez,+A\">Aurelien Rodriguez\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Gregerson,+A\">Austen Gregerson\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Spataru,+A\">Ava Spataru\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Roziere,+B\">Baptiste Roziere\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Biron,+B\">Bethany Biron\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Tang,+B\">Binh Tang\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Chern,+B\">Bobbie Chern\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Caucheteux,+C\">Charlotte Caucheteux\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Nayak,+C\">Chaya Nayak\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Bi,+C\">Chloe Bi\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Marra,+C\">Chris Marra\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=McConnell,+C\">Chris McConnell\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Keller,+C\">Christian Keller\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Touret,+C\">Christophe Touret\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Wu,+C\">Chunyang Wu\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Wong,+C\">Corinne Wong\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Ferrer,+C+C\">Cristian Canton Ferrer\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Nikolaidis,+C\">Cyrus Nikolaidis\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Allonsius,+D\">Damien Allonsius\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Song,+D\">Daniel Song\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Pintz,+D\">Danielle Pintz\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Livshits,+D\">Danny Livshits\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Wyatt,+D\">Danny Wyatt\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Esiobu,+D\">David Esiobu\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Choudhary,+D\">Dhruv Choudhary\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Mahajan,+D\">Dhruv Mahajan\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Garcia-Olano,+D\">Diego Garcia-Olano\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Perino,+D\">Diego Perino\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Hupkes,+D\">Dieuwke Hupkes\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Lakomkin,+E\">Egor Lakomkin\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=AlBadawy,+E\">Ehab AlBadawy\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Lobanova,+E\">Elina Lobanova\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Dinan,+E\">Emily Dinan\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Smith,+E+M\">Eric Michael Smith\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Radenovic,+F\">Filip Radenovic\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Guzm%C3%A1n,+F\">Francisco Guzmán\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Zhang,+F\">Frank Zhang\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Synnaeve,+G\">Gabriel Synnaeve\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Lee,+G\">Gabrielle Lee\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Anderson,+G+L\">Georgia Lewis Anderson\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Thattai,+G\">Govind Thattai\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Nail,+G\">Graeme Nail\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Mialon,+G\">Gregoire Mialon\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Pang,+G\">Guan Pang\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Cucurell,+G\">Guillem Cucurell\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Nguyen,+H\">Hailey Nguyen\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Korevaar,+H\">Hannah Korevaar\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Xu,+H\">Hu Xu\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Touvron,+H\">Hugo Touvron\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Zarov,+I\">Iliyan Zarov\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Ibarra,+I+A\">Imanol Arrieta Ibarra\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Kloumann,+I\">Isabel Kloumann\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Misra,+I\">Ishan Misra\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Evtimov,+I\">Ivan Evtimov\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Zhang,+J\">Jack Zhang\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Copet,+J\">Jade Copet\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Lee,+J\">Jaewon Lee\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Geffert,+J\">Jan Geffert\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Vranes,+J\">Jana Vranes\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Park,+J\">Jason Park\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Mahadeokar,+J\">Jay Mahadeokar\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Shah,+J\">Jeet Shah\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=van+der+Linde,+J\">Jelmer van der Linde\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Billock,+J\">Jennifer Billock\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Hong,+J\">Jenny Hong\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Lee,+J\">Jenya Lee\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Fu,+J\">Jeremy Fu\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Chi,+J\">Jianfeng Chi\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Huang,+J\">Jianyu Huang\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Liu,+J\">Jiawen Liu\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Wang,+J\">Jie Wang\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Yu,+J\">Jiecao Yu\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Bitton,+J\">Joanna Bitton\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Spisak,+J\">Joe Spisak\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Park,+J\">Jongsoo Park\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Rocca,+J\">Joseph Rocca\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Johnstun,+J\">Joshua Johnstun\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Saxe,+J\">Joshua Saxe\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Jia,+J\">Junteng Jia\u003C/a> et al. (460 additional authors not shown)\u003C/p>",{"headings":87,"localImagePaths":116,"remoteImagePaths":117,"frontmatter":118,"imagePaths":119},[88,91,92,94,96,98,100,102,105,108,110,112,113],{"depth":24,"slug":89,"text":90},"arxiv","arXiv",{"depth":24,"slug":30,"text":30},{"depth":24,"slug":93,"text":93},"学習方法",{"depth":24,"slug":95,"text":95},"開発における3つの主要要素",{"depth":35,"slug":97,"text":97},"データ",{"depth":35,"slug":99,"text":99},"スケール",{"depth":35,"slug":101,"text":101},"複雑性の管理",{"depth":24,"slug":103,"text":104},"llama-2からの変更点","Llama 2からの変更点",{"depth":35,"slug":106,"text":107},"ppo--dpo","PPO → DPO",{"depth":35,"slug":109,"text":109},"データ量",{"depth":35,"slug":111,"text":111},"モデルアーキテクチャの微変更",{"depth":24,"slug":70,"text":70},{"depth":24,"slug":114,"text":115},"著者多すぎ","著者(多すぎ)",[],[],{"title":79,"date":80},[],"The Llama 3 Herd of Models(2024).md","sudden-drops-in-the-loss-_-syntax-acquisition-phase-transitions-and-simplicity-bias-in-mlms-2024",{"id":121,"data":123,"body":126,"filePath":127,"digest":128,"rendered":129,"legacyId":165},{"title":124,"date":125},"Sudden Drops in the Loss: Syntax Acquisition, Phase Transitions, and Simplicity Bias in MLMs (2024)","2025-06-08","## arXiv\nhttps://arxiv.org/abs/2309.07311\n\n## 著者\n[Angelica Chen](https://openreview.net/profile?id=~Angelica_Chen1), [Ravid Shwartz-Ziv](https://openreview.net/profile?id=~Ravid_Shwartz-Ziv2), [Kyunghyun Cho](https://openreview.net/profile?id=~Kyunghyun_Cho1), [Matthew L Leavitt](https://openreview.net/profile?id=~Matthew_L_Leavitt1), [Naomi Saphra](https://openreview.net/profile?id=~Naomi_Saphra1)\n\n## 要約\n- BERTとかのMLMの学習過程で、短い期間でSASを獲得する傾向がある\n- SASを獲得すると損失が急激に低下し、言語能力の獲得を促進\n- SASは訓練中に操作可能\n\t- 抑制すると複雑な言語能力の出現が妨げられる\n\t- 初期段階で一時的に抑制するとモデルの品質向上、収束の加速が見られた\n\n## 用語とか\n### MLM (Masked Language Model)\n- 文章中の一部の単語を隠して、その隠された単語を予測させるタスクを通じて言語を学習するモデル\n- BERTなど\n- 文の前後両方の文脈を同時に考慮できる\n### SAS(Syntactic Attention Structure)\n- モデルが特定の構文的な依存関係に注目したアテンションヘッドを形成する傾向\n- MLMの学習時に明示的な帰納バイアスなしに自然発生\n- SASの発現を制御→MLMの内部構造の特性と外的な能力の関係を観察\n![SASの概念図](/images/スクリーンショット%202025-06-08%2021.04.25.png)\n\n### UAS(unlabeld attatchment score)\n- SASの定量化\n- 言語モデルが構文解析の結果と同じように単語にアテンションを当てられているか\n- 構文解析の結果と比較して予測が成功した割合を計算\n### 相転移\n- 非連続的な過程\n- 知識の発見はスケーリング則に従わず唐突な変化を見せる\n\n## SASを調整する手法\n$$\nL(x) = L_{MLM}(x) + \\lambda \\sum^{|x|}_{i=1} \\sum_{x_{j} \\in D(x_i)} \\gamma(x_i, x_j)\n$$\n- 構文性スコア$\\gamma(x_i, x_j)$を用いた正則化項を$\\lambda$でスケーリング\n\t- $\\lambda \u003C 0$: SASを促進\n\t- $\\lambda > 0$: SASを抑制\n- $\\gamma(x_i, x_j)$: 構文的に関係のある単語$i,j$間の最大アテンションの重み\n\n## SASを初期段階で抑制するとモデル品質が向上する理由\n- 代替戦略の獲得\n\t- ざっくりSASじゃない戦略のこと\n\t- 長距離の文脈を利用する戦略\n- SASをよりよく学ぶための踏み台的な\n\n## 結論\n### 単純性バイアスとの関係\n- モデルは学習初期でSASのような解釈しやすく単純な回を好む傾向があり\n- これに固執すると長期的な性能向上を妨げる可能性\n### 学習の臨界点\n- フェーズ遷移(損失が急落するところ)が起きている最中に学習方法を変更するとモデルの性能が最も下がる\n- 臨界点は非常に不安定\n\n## 感想\n- 学習過程での構文の獲得過程みたいなものが見れておもろい\n- 最初はSASを抑制した方がいいみたいなのはwarmupとかと繋がるのかな？\n- 長期的に性能をあげるための工夫が大事","src/content/papers/Sudden Drops in the Loss _ Syntax Acquisition, Phase Transitions, and Simplicity Bias in MLMs (2024).md","45a5f61c8070786e",{"html":130,"metadata":131},"\u003Ch2 id=\"arxiv\">arXiv\u003C/h2>\n\u003Cp>\u003Ca href=\"https://arxiv.org/abs/2309.07311\">https://arxiv.org/abs/2309.07311\u003C/a>\u003C/p>\n\u003Ch2 id=\"著者\">著者\u003C/h2>\n\u003Cp>\u003Ca href=\"https://openreview.net/profile?id=~Angelica_Chen1\">Angelica Chen\u003C/a>, \u003Ca href=\"https://openreview.net/profile?id=~Ravid_Shwartz-Ziv2\">Ravid Shwartz-Ziv\u003C/a>, \u003Ca href=\"https://openreview.net/profile?id=~Kyunghyun_Cho1\">Kyunghyun Cho\u003C/a>, \u003Ca href=\"https://openreview.net/profile?id=~Matthew_L_Leavitt1\">Matthew L Leavitt\u003C/a>, \u003Ca href=\"https://openreview.net/profile?id=~Naomi_Saphra1\">Naomi Saphra\u003C/a>\u003C/p>\n\u003Ch2 id=\"要約\">要約\u003C/h2>\n\u003Cul>\n\u003Cli>BERTとかのMLMの学習過程で、短い期間でSASを獲得する傾向がある\u003C/li>\n\u003Cli>SASを獲得すると損失が急激に低下し、言語能力の獲得を促進\u003C/li>\n\u003Cli>SASは訓練中に操作可能\n\u003Cul>\n\u003Cli>抑制すると複雑な言語能力の出現が妨げられる\u003C/li>\n\u003Cli>初期段階で一時的に抑制するとモデルの品質向上、収束の加速が見られた\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"用語とか\">用語とか\u003C/h2>\n\u003Ch3 id=\"mlm-masked-language-model\">MLM (Masked Language Model)\u003C/h3>\n\u003Cul>\n\u003Cli>文章中の一部の単語を隠して、その隠された単語を予測させるタスクを通じて言語を学習するモデル\u003C/li>\n\u003Cli>BERTなど\u003C/li>\n\u003Cli>文の前後両方の文脈を同時に考慮できる\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"sassyntactic-attention-structure\">SAS(Syntactic Attention Structure)\u003C/h3>\n\u003Cul>\n\u003Cli>モデルが特定の構文的な依存関係に注目したアテンションヘッドを形成する傾向\u003C/li>\n\u003Cli>MLMの学習時に明示的な帰納バイアスなしに自然発生\u003C/li>\n\u003Cli>SASの発現を制御→MLMの内部構造の特性と外的な能力の関係を観察\n\u003Cimg src=\"/images/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88%202025-06-08%2021.04.25.png\" alt=\"SASの概念図\">\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"uasunlabeld-attatchment-score\">UAS(unlabeld attatchment score)\u003C/h3>\n\u003Cul>\n\u003Cli>SASの定量化\u003C/li>\n\u003Cli>言語モデルが構文解析の結果と同じように単語にアテンションを当てられているか\u003C/li>\n\u003Cli>構文解析の結果と比較して予測が成功した割合を計算\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"相転移\">相転移\u003C/h3>\n\u003Cul>\n\u003Cli>非連続的な過程\u003C/li>\n\u003Cli>知識の発見はスケーリング則に従わず唐突な変化を見せる\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"sasを調整する手法\">SASを調整する手法\u003C/h2>\n\u003Cspan class=\"katex-display\">\u003Cspan class=\"katex\">\u003Cspan class=\"katex-mathml\">\u003Cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\u003Csemantics>\u003Cmrow>\u003Cmi>L\u003C/mi>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmi>x\u003C/mi>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003Cmo>=\u003C/mo>\u003Cmsub>\u003Cmi>L\u003C/mi>\u003Cmrow>\u003Cmi>M\u003C/mi>\u003Cmi>L\u003C/mi>\u003Cmi>M\u003C/mi>\u003C/mrow>\u003C/msub>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmi>x\u003C/mi>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003Cmo>+\u003C/mo>\u003Cmi>λ\u003C/mi>\u003Cmunderover>\u003Cmo>∑\u003C/mo>\u003Cmrow>\u003Cmi>i\u003C/mi>\u003Cmo>=\u003C/mo>\u003Cmn>1\u003C/mn>\u003C/mrow>\u003Cmrow>\u003Cmi mathvariant=\"normal\">∣\u003C/mi>\u003Cmi>x\u003C/mi>\u003Cmi mathvariant=\"normal\">∣\u003C/mi>\u003C/mrow>\u003C/munderover>\u003Cmunder>\u003Cmo>∑\u003C/mo>\u003Cmrow>\u003Cmsub>\u003Cmi>x\u003C/mi>\u003Cmi>j\u003C/mi>\u003C/msub>\u003Cmo>∈\u003C/mo>\u003Cmi>D\u003C/mi>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmsub>\u003Cmi>x\u003C/mi>\u003Cmi>i\u003C/mi>\u003C/msub>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003C/munder>\u003Cmi>γ\u003C/mi>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmsub>\u003Cmi>x\u003C/mi>\u003Cmi>i\u003C/mi>\u003C/msub>\u003Cmo separator=\"true\">,\u003C/mo>\u003Cmsub>\u003Cmi>x\u003C/mi>\u003Cmi>j\u003C/mi>\u003C/msub>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003Cannotation encoding=\"application/x-tex\">L(x) = L_{MLM}(x) + \\lambda \\sum^{|x|}_{i=1} \\sum_{x_{j} \\in D(x_i)} \\gamma(x_i, x_j)\u003C/annotation>\u003C/semantics>\u003C/math>\u003C/span>\u003Cspan class=\"katex-html\" aria-hidden=\"true\">\u003Cspan class=\"base\">\u003Cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\">\u003C/span>\u003Cspan class=\"mord mathnormal\">L\u003C/span>\u003Cspan class=\"mopen\">(\u003C/span>\u003Cspan class=\"mord mathnormal\">x\u003C/span>\u003Cspan class=\"mclose\">)\u003C/span>\u003Cspan class=\"mspace\" style=\"margin-right:0.2778em;\">\u003C/span>\u003Cspan class=\"mrel\">=\u003C/span>\u003Cspan class=\"mspace\" style=\"margin-right:0.2778em;\">\u003C/span>\u003C/span>\u003Cspan class=\"base\">\u003Cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\">\u003C/span>\u003Cspan class=\"mord\">\u003Cspan class=\"mord mathnormal\">L\u003C/span>\u003Cspan class=\"msupsub\">\u003Cspan class=\"vlist-t vlist-t2\">\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.3283em;\">\u003Cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\">\u003Cspan class=\"pstrut\" style=\"height:2.7em;\">\u003C/span>\u003Cspan class=\"sizing reset-size6 size3 mtight\">\u003Cspan class=\"mord mtight\">\u003Cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">M\u003C/span>\u003Cspan class=\"mord mathnormal mtight\">L\u003C/span>\u003Cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">M\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"vlist-s\">​\u003C/span>\u003C/span>\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.15em;\">\u003Cspan>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"mopen\">(\u003C/span>\u003Cspan class=\"mord mathnormal\">x\u003C/span>\u003Cspan class=\"mclose\">)\u003C/span>\u003Cspan class=\"mspace\" style=\"margin-right:0.2222em;\">\u003C/span>\u003Cspan class=\"mbin\">+\u003C/span>\u003Cspan class=\"mspace\" style=\"margin-right:0.2222em;\">\u003C/span>\u003C/span>\u003Cspan class=\"base\">\u003Cspan class=\"strut\" style=\"height:3.4993em;vertical-align:-1.5383em;\">\u003C/span>\u003Cspan class=\"mord mathnormal\">λ\u003C/span>\u003Cspan class=\"mspace\" style=\"margin-right:0.1667em;\">\u003C/span>\u003Cspan class=\"mop op-limits\">\u003Cspan class=\"vlist-t vlist-t2\">\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:1.961em;\">\u003Cspan style=\"top:-1.8723em;margin-left:0em;\">\u003Cspan class=\"pstrut\" style=\"height:3.05em;\">\u003C/span>\u003Cspan class=\"sizing reset-size6 size3 mtight\">\u003Cspan class=\"mord mtight\">\u003Cspan class=\"mord mathnormal mtight\">i\u003C/span>\u003Cspan class=\"mrel mtight\">=\u003C/span>\u003Cspan class=\"mord mtight\">1\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan style=\"top:-3.05em;\">\u003Cspan class=\"pstrut\" style=\"height:3.05em;\">\u003C/span>\u003Cspan>\u003Cspan class=\"mop op-symbol large-op\">∑\u003C/span>\u003C/span>\u003C/span>\u003Cspan style=\"top:-4.386em;margin-left:0em;\">\u003Cspan class=\"pstrut\" style=\"height:3.05em;\">\u003C/span>\u003Cspan class=\"sizing reset-size6 size3 mtight\">\u003Cspan class=\"mord mtight\">\u003Cspan class=\"mord mtight\">∣\u003C/span>\u003Cspan class=\"mord mathnormal mtight\">x\u003C/span>\u003Cspan class=\"mord mtight\">∣\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"vlist-s\">​\u003C/span>\u003C/span>\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:1.2777em;\">\u003Cspan>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"mspace\" style=\"margin-right:0.1667em;\">\u003C/span>\u003Cspan class=\"mop op-limits\">\u003Cspan class=\"vlist-t vlist-t2\">\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:1.05em;\">\u003Cspan style=\"top:-1.809em;margin-left:0em;\">\u003Cspan class=\"pstrut\" style=\"height:3.05em;\">\u003C/span>\u003Cspan class=\"sizing reset-size6 size3 mtight\">\u003Cspan class=\"mord mtight\">\u003Cspan class=\"mord mtight\">\u003Cspan class=\"mord mathnormal mtight\">x\u003C/span>\u003Cspan class=\"msupsub\">\u003Cspan class=\"vlist-t vlist-t2\">\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.3281em;\">\u003Cspan style=\"top:-2.357em;margin-left:0em;margin-right:0.0714em;\">\u003Cspan class=\"pstrut\" style=\"height:2.5em;\">\u003C/span>\u003Cspan class=\"sizing reset-size3 size1 mtight\">\u003Cspan class=\"mord mtight\">\u003Cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"vlist-s\">​\u003C/span>\u003C/span>\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.2819em;\">\u003Cspan>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"mrel mtight\">∈\u003C/span>\u003Cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">D\u003C/span>\u003Cspan class=\"mopen mtight\">(\u003C/span>\u003Cspan class=\"mord mtight\">\u003Cspan class=\"mord mathnormal mtight\">x\u003C/span>\u003Cspan class=\"msupsub\">\u003Cspan class=\"vlist-t vlist-t2\">\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.3281em;\">\u003Cspan style=\"top:-2.357em;margin-left:0em;margin-right:0.0714em;\">\u003Cspan class=\"pstrut\" style=\"height:2.5em;\">\u003C/span>\u003Cspan class=\"sizing reset-size3 size1 mtight\">\u003Cspan class=\"mord mathnormal mtight\">i\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"vlist-s\">​\u003C/span>\u003C/span>\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.143em;\">\u003Cspan>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"mclose mtight\">)\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan style=\"top:-3.05em;\">\u003Cspan class=\"pstrut\" style=\"height:3.05em;\">\u003C/span>\u003Cspan>\u003Cspan class=\"mop op-symbol large-op\">∑\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"vlist-s\">​\u003C/span>\u003C/span>\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:1.5383em;\">\u003Cspan>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"mspace\" style=\"margin-right:0.1667em;\">\u003C/span>\u003Cspan class=\"mord mathnormal\" style=\"margin-right:0.05556em;\">γ\u003C/span>\u003Cspan class=\"mopen\">(\u003C/span>\u003Cspan class=\"mord\">\u003Cspan class=\"mord mathnormal\">x\u003C/span>\u003Cspan class=\"msupsub\">\u003Cspan class=\"vlist-t vlist-t2\">\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.3117em;\">\u003Cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\">\u003Cspan class=\"pstrut\" style=\"height:2.7em;\">\u003C/span>\u003Cspan class=\"sizing reset-size6 size3 mtight\">\u003Cspan class=\"mord mathnormal mtight\">i\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"vlist-s\">​\u003C/span>\u003C/span>\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.15em;\">\u003Cspan>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"mpunct\">,\u003C/span>\u003Cspan class=\"mspace\" style=\"margin-right:0.1667em;\">\u003C/span>\u003Cspan class=\"mord\">\u003Cspan class=\"mord mathnormal\">x\u003C/span>\u003Cspan class=\"msupsub\">\u003Cspan class=\"vlist-t vlist-t2\">\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.3117em;\">\u003Cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\">\u003Cspan class=\"pstrut\" style=\"height:2.7em;\">\u003C/span>\u003Cspan class=\"sizing reset-size6 size3 mtight\">\u003Cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"vlist-s\">​\u003C/span>\u003C/span>\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.2861em;\">\u003Cspan>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"mclose\">)\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\n\u003Cul>\n\u003Cli>構文性スコア\u003Cspan class=\"katex\">\u003Cspan class=\"katex-mathml\">\u003Cmath xmlns=\"http://www.w3.org/1998/Math/MathML\">\u003Csemantics>\u003Cmrow>\u003Cmi>γ\u003C/mi>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmsub>\u003Cmi>x\u003C/mi>\u003Cmi>i\u003C/mi>\u003C/msub>\u003Cmo separator=\"true\">,\u003C/mo>\u003Cmsub>\u003Cmi>x\u003C/mi>\u003Cmi>j\u003C/mi>\u003C/msub>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003Cannotation encoding=\"application/x-tex\">\\gamma(x_i, x_j)\u003C/annotation>\u003C/semantics>\u003C/math>\u003C/span>\u003Cspan class=\"katex-html\" aria-hidden=\"true\">\u003Cspan class=\"base\">\u003Cspan class=\"strut\" style=\"height:1.0361em;vertical-align:-0.2861em;\">\u003C/span>\u003Cspan class=\"mord mathnormal\" style=\"margin-right:0.05556em;\">γ\u003C/span>\u003Cspan class=\"mopen\">(\u003C/span>\u003Cspan class=\"mord\">\u003Cspan class=\"mord mathnormal\">x\u003C/span>\u003Cspan class=\"msupsub\">\u003Cspan class=\"vlist-t vlist-t2\">\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.3117em;\">\u003Cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\">\u003Cspan class=\"pstrut\" style=\"height:2.7em;\">\u003C/span>\u003Cspan class=\"sizing reset-size6 size3 mtight\">\u003Cspan class=\"mord mathnormal mtight\">i\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"vlist-s\">​\u003C/span>\u003C/span>\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.15em;\">\u003Cspan>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"mpunct\">,\u003C/span>\u003Cspan class=\"mspace\" style=\"margin-right:0.1667em;\">\u003C/span>\u003Cspan class=\"mord\">\u003Cspan class=\"mord mathnormal\">x\u003C/span>\u003Cspan class=\"msupsub\">\u003Cspan class=\"vlist-t vlist-t2\">\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.3117em;\">\u003Cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\">\u003Cspan class=\"pstrut\" style=\"height:2.7em;\">\u003C/span>\u003Cspan class=\"sizing reset-size6 size3 mtight\">\u003Cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"vlist-s\">​\u003C/span>\u003C/span>\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.2861em;\">\u003Cspan>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"mclose\">)\u003C/span>\u003C/span>\u003C/span>\u003C/span>を用いた正則化項を\u003Cspan class=\"katex\">\u003Cspan class=\"katex-mathml\">\u003Cmath xmlns=\"http://www.w3.org/1998/Math/MathML\">\u003Csemantics>\u003Cmrow>\u003Cmi>λ\u003C/mi>\u003C/mrow>\u003Cannotation encoding=\"application/x-tex\">\\lambda\u003C/annotation>\u003C/semantics>\u003C/math>\u003C/span>\u003Cspan class=\"katex-html\" aria-hidden=\"true\">\u003Cspan class=\"base\">\u003Cspan class=\"strut\" style=\"height:0.6944em;\">\u003C/span>\u003Cspan class=\"mord mathnormal\">λ\u003C/span>\u003C/span>\u003C/span>\u003C/span>でスケーリング\n\u003Cul>\n\u003Cli>\u003Cspan class=\"katex\">\u003Cspan class=\"katex-mathml\">\u003Cmath xmlns=\"http://www.w3.org/1998/Math/MathML\">\u003Csemantics>\u003Cmrow>\u003Cmi>λ\u003C/mi>\u003Cmo>&#x3C;\u003C/mo>\u003Cmn>0\u003C/mn>\u003C/mrow>\u003Cannotation encoding=\"application/x-tex\">\\lambda &#x3C; 0\u003C/annotation>\u003C/semantics>\u003C/math>\u003C/span>\u003Cspan class=\"katex-html\" aria-hidden=\"true\">\u003Cspan class=\"base\">\u003Cspan class=\"strut\" style=\"height:0.7335em;vertical-align:-0.0391em;\">\u003C/span>\u003Cspan class=\"mord mathnormal\">λ\u003C/span>\u003Cspan class=\"mspace\" style=\"margin-right:0.2778em;\">\u003C/span>\u003Cspan class=\"mrel\">&#x3C;\u003C/span>\u003Cspan class=\"mspace\" style=\"margin-right:0.2778em;\">\u003C/span>\u003C/span>\u003Cspan class=\"base\">\u003Cspan class=\"strut\" style=\"height:0.6444em;\">\u003C/span>\u003Cspan class=\"mord\">0\u003C/span>\u003C/span>\u003C/span>\u003C/span>: SASを促進\u003C/li>\n\u003Cli>\u003Cspan class=\"katex\">\u003Cspan class=\"katex-mathml\">\u003Cmath xmlns=\"http://www.w3.org/1998/Math/MathML\">\u003Csemantics>\u003Cmrow>\u003Cmi>λ\u003C/mi>\u003Cmo>>\u003C/mo>\u003Cmn>0\u003C/mn>\u003C/mrow>\u003Cannotation encoding=\"application/x-tex\">\\lambda > 0\u003C/annotation>\u003C/semantics>\u003C/math>\u003C/span>\u003Cspan class=\"katex-html\" aria-hidden=\"true\">\u003Cspan class=\"base\">\u003Cspan class=\"strut\" style=\"height:0.7335em;vertical-align:-0.0391em;\">\u003C/span>\u003Cspan class=\"mord mathnormal\">λ\u003C/span>\u003Cspan class=\"mspace\" style=\"margin-right:0.2778em;\">\u003C/span>\u003Cspan class=\"mrel\">>\u003C/span>\u003Cspan class=\"mspace\" style=\"margin-right:0.2778em;\">\u003C/span>\u003C/span>\u003Cspan class=\"base\">\u003Cspan class=\"strut\" style=\"height:0.6444em;\">\u003C/span>\u003Cspan class=\"mord\">0\u003C/span>\u003C/span>\u003C/span>\u003C/span>: SASを抑制\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\u003Cspan class=\"katex\">\u003Cspan class=\"katex-mathml\">\u003Cmath xmlns=\"http://www.w3.org/1998/Math/MathML\">\u003Csemantics>\u003Cmrow>\u003Cmi>γ\u003C/mi>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmsub>\u003Cmi>x\u003C/mi>\u003Cmi>i\u003C/mi>\u003C/msub>\u003Cmo separator=\"true\">,\u003C/mo>\u003Cmsub>\u003Cmi>x\u003C/mi>\u003Cmi>j\u003C/mi>\u003C/msub>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003Cannotation encoding=\"application/x-tex\">\\gamma(x_i, x_j)\u003C/annotation>\u003C/semantics>\u003C/math>\u003C/span>\u003Cspan class=\"katex-html\" aria-hidden=\"true\">\u003Cspan class=\"base\">\u003Cspan class=\"strut\" style=\"height:1.0361em;vertical-align:-0.2861em;\">\u003C/span>\u003Cspan class=\"mord mathnormal\" style=\"margin-right:0.05556em;\">γ\u003C/span>\u003Cspan class=\"mopen\">(\u003C/span>\u003Cspan class=\"mord\">\u003Cspan class=\"mord mathnormal\">x\u003C/span>\u003Cspan class=\"msupsub\">\u003Cspan class=\"vlist-t vlist-t2\">\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.3117em;\">\u003Cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\">\u003Cspan class=\"pstrut\" style=\"height:2.7em;\">\u003C/span>\u003Cspan class=\"sizing reset-size6 size3 mtight\">\u003Cspan class=\"mord mathnormal mtight\">i\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"vlist-s\">​\u003C/span>\u003C/span>\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.15em;\">\u003Cspan>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"mpunct\">,\u003C/span>\u003Cspan class=\"mspace\" style=\"margin-right:0.1667em;\">\u003C/span>\u003Cspan class=\"mord\">\u003Cspan class=\"mord mathnormal\">x\u003C/span>\u003Cspan class=\"msupsub\">\u003Cspan class=\"vlist-t vlist-t2\">\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.3117em;\">\u003Cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\">\u003Cspan class=\"pstrut\" style=\"height:2.7em;\">\u003C/span>\u003Cspan class=\"sizing reset-size6 size3 mtight\">\u003Cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"vlist-s\">​\u003C/span>\u003C/span>\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.2861em;\">\u003Cspan>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"mclose\">)\u003C/span>\u003C/span>\u003C/span>\u003C/span>: 構文的に関係のある単語\u003Cspan class=\"katex\">\u003Cspan class=\"katex-mathml\">\u003Cmath xmlns=\"http://www.w3.org/1998/Math/MathML\">\u003Csemantics>\u003Cmrow>\u003Cmi>i\u003C/mi>\u003Cmo separator=\"true\">,\u003C/mo>\u003Cmi>j\u003C/mi>\u003C/mrow>\u003Cannotation encoding=\"application/x-tex\">i,j\u003C/annotation>\u003C/semantics>\u003C/math>\u003C/span>\u003Cspan class=\"katex-html\" aria-hidden=\"true\">\u003Cspan class=\"base\">\u003Cspan class=\"strut\" style=\"height:0.854em;vertical-align:-0.1944em;\">\u003C/span>\u003Cspan class=\"mord mathnormal\">i\u003C/span>\u003Cspan class=\"mpunct\">,\u003C/span>\u003Cspan class=\"mspace\" style=\"margin-right:0.1667em;\">\u003C/span>\u003Cspan class=\"mord mathnormal\" style=\"margin-right:0.05724em;\">j\u003C/span>\u003C/span>\u003C/span>\u003C/span>間の最大アテンションの重み\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"sasを初期段階で抑制するとモデル品質が向上する理由\">SASを初期段階で抑制するとモデル品質が向上する理由\u003C/h2>\n\u003Cul>\n\u003Cli>代替戦略の獲得\n\u003Cul>\n\u003Cli>ざっくりSASじゃない戦略のこと\u003C/li>\n\u003Cli>長距離の文脈を利用する戦略\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>SASをよりよく学ぶための踏み台的な\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"結論\">結論\u003C/h2>\n\u003Ch3 id=\"単純性バイアスとの関係\">単純性バイアスとの関係\u003C/h3>\n\u003Cul>\n\u003Cli>モデルは学習初期でSASのような解釈しやすく単純な回を好む傾向があり\u003C/li>\n\u003Cli>これに固執すると長期的な性能向上を妨げる可能性\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"学習の臨界点\">学習の臨界点\u003C/h3>\n\u003Cul>\n\u003Cli>フェーズ遷移(損失が急落するところ)が起きている最中に学習方法を変更するとモデルの性能が最も下がる\u003C/li>\n\u003Cli>臨界点は非常に不安定\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"感想\">感想\u003C/h2>\n\u003Cul>\n\u003Cli>学習過程での構文の獲得過程みたいなものが見れておもろい\u003C/li>\n\u003Cli>最初はSASを抑制した方がいいみたいなのはwarmupとかと繋がるのかな？\u003C/li>\n\u003Cli>長期的に性能をあげるための工夫が大事\u003C/li>\n\u003C/ul>",{"headings":132,"localImagePaths":161,"remoteImagePaths":162,"frontmatter":163,"imagePaths":164},[133,134,135,136,138,141,144,147,149,152,155,156,158,160],{"depth":24,"slug":89,"text":90},{"depth":24,"slug":25,"text":25},{"depth":24,"slug":30,"text":30},{"depth":24,"slug":137,"text":137},"用語とか",{"depth":35,"slug":139,"text":140},"mlm-masked-language-model","MLM (Masked Language Model)",{"depth":35,"slug":142,"text":143},"sassyntactic-attention-structure","SAS(Syntactic Attention Structure)",{"depth":35,"slug":145,"text":146},"uasunlabeld-attatchment-score","UAS(unlabeld attatchment score)",{"depth":35,"slug":148,"text":148},"相転移",{"depth":24,"slug":150,"text":151},"sasを調整する手法","SASを調整する手法",{"depth":24,"slug":153,"text":154},"sasを初期段階で抑制するとモデル品質が向上する理由","SASを初期段階で抑制するとモデル品質が向上する理由",{"depth":24,"slug":68,"text":68},{"depth":35,"slug":157,"text":157},"単純性バイアスとの関係",{"depth":35,"slug":159,"text":159},"学習の臨界点",{"depth":24,"slug":70,"text":70},[],[],{"title":124,"date":125},[],"Sudden Drops in the Loss _ Syntax Acquisition, Phase Transitions, and Simplicity Bias in MLMs (2024).md","interpretability-of-language-models-via-task-spaces",{"id":166,"data":168,"body":171,"filePath":172,"digest":173,"rendered":174,"legacyId":199},{"title":169,"date":170},"Interpretability of Language Models via Task Spaces","2025-06-20","## arXiv\nhttps://arxiv.org/abs/2406.06441\n\n## 著者\n[Lucas Weber](https://arxiv.org/search/cs?searchtype=author&query=Weber,+L), [Jaap Jumelet](https://arxiv.org/search/cs?searchtype=author&query=Jumelet,+J), [Elia Bruni](https://arxiv.org/search/cs?searchtype=author&query=Bruni,+E), [Dieuwke Hupkes](https://arxiv.org/search/cs?searchtype=author&query=Hupkes,+D)\n\n## 要約\n- 入出力のベンチマークじゃない方法でモデルの解釈をしたい\n- linguistic task spaces (言語タスク空間)の提案\n\t- LMが内部的にどのように言語現象を理解・関連付けているかを空間的に表現したもの\n\t- Transfer-based similarity probing, Gradient-based similarity probingで構築\n\t- 各タスクがどの程度似ているかを測定して、タスク間の類似性空間みたいなものをつくる\n- FTGD (Fine-Tuning via Gradient Difference)\n\t- 特定の言語現象のみを選択的にFine Tuningする方法の提案\n\t- 文法的例文と非文法的例文のペアから、勾配差分(Gradient Difference)を用いて差が顕著なパラメータのみを抽出してモデルを更新\n- モデルサイズが大きくなるとより抽象的な言語構造の一般化能力が向上\n\t- 関連するタスク間でのパラメータ共有が増加\n\n## FTGD\n- minimal pairをつかう\n\t- John did not see anything. (文法的)\n\t- John did see anything. (非文法的)\n- この2つの勾配の差はその言語タスクによる学習のみを取り出したと言える\n- さらに勾配差分が大きい部分のみを使うことで効率をよくしつつ情報量を保持\n\n## Similarity Probing\n- ある言語タスクが他のタスクにどう影響するかを測りたい\n- Transfer Probing\n\t- タスクAでFTGDした時のタスクBの性能変化を見る\n- Gradient Probing\n\t- タスクAとタスクBの勾配のサブスペースを比較\n\t- ざっくりどのぐらいパラメータの共有があるかという感じ\n\n## 結果\n### FTGDは全勾配のfine-tuningと同じぐらいの精度\n- 各タスクの精度は保ったまま、Perplexityの増加を抑制\n- 目的タスクの改善のみが行えていそう\n### タスク空間は語彙ではなく言語構造でクラスタ化\n-  より抽象的な言語概念を共有パラメータとしてる説\n- モデル規模が大きいほどより抽象概念を一般化\n\n## 感想\n- 単純に語彙が似てるからではなく、文法的な現象に着目しているのは興味深い\n- 言語分野のタスクのみに着目していたので、汎用的なタスク空間みたいなのをつくれたらおもしろそう","src/content/papers/Interpretability of Language Models via Task Spaces.md","54b4feab7f93b2f7",{"html":175,"metadata":176},"\u003Ch2 id=\"arxiv\">arXiv\u003C/h2>\n\u003Cp>\u003Ca href=\"https://arxiv.org/abs/2406.06441\">https://arxiv.org/abs/2406.06441\u003C/a>\u003C/p>\n\u003Ch2 id=\"著者\">著者\u003C/h2>\n\u003Cp>\u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Weber,+L\">Lucas Weber\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Jumelet,+J\">Jaap Jumelet\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Bruni,+E\">Elia Bruni\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Hupkes,+D\">Dieuwke Hupkes\u003C/a>\u003C/p>\n\u003Ch2 id=\"要約\">要約\u003C/h2>\n\u003Cul>\n\u003Cli>入出力のベンチマークじゃない方法でモデルの解釈をしたい\u003C/li>\n\u003Cli>linguistic task spaces (言語タスク空間)の提案\n\u003Cul>\n\u003Cli>LMが内部的にどのように言語現象を理解・関連付けているかを空間的に表現したもの\u003C/li>\n\u003Cli>Transfer-based similarity probing, Gradient-based similarity probingで構築\u003C/li>\n\u003Cli>各タスクがどの程度似ているかを測定して、タスク間の類似性空間みたいなものをつくる\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>FTGD (Fine-Tuning via Gradient Difference)\n\u003Cul>\n\u003Cli>特定の言語現象のみを選択的にFine Tuningする方法の提案\u003C/li>\n\u003Cli>文法的例文と非文法的例文のペアから、勾配差分(Gradient Difference)を用いて差が顕著なパラメータのみを抽出してモデルを更新\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>モデルサイズが大きくなるとより抽象的な言語構造の一般化能力が向上\n\u003Cul>\n\u003Cli>関連するタスク間でのパラメータ共有が増加\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"ftgd\">FTGD\u003C/h2>\n\u003Cul>\n\u003Cli>minimal pairをつかう\n\u003Cul>\n\u003Cli>John did not see anything. (文法的)\u003C/li>\n\u003Cli>John did see anything. (非文法的)\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>この2つの勾配の差はその言語タスクによる学習のみを取り出したと言える\u003C/li>\n\u003Cli>さらに勾配差分が大きい部分のみを使うことで効率をよくしつつ情報量を保持\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"similarity-probing\">Similarity Probing\u003C/h2>\n\u003Cul>\n\u003Cli>ある言語タスクが他のタスクにどう影響するかを測りたい\u003C/li>\n\u003Cli>Transfer Probing\n\u003Cul>\n\u003Cli>タスクAでFTGDした時のタスクBの性能変化を見る\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>Gradient Probing\n\u003Cul>\n\u003Cli>タスクAとタスクBの勾配のサブスペースを比較\u003C/li>\n\u003Cli>ざっくりどのぐらいパラメータの共有があるかという感じ\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"結果\">結果\u003C/h2>\n\u003Ch3 id=\"ftgdは全勾配のfine-tuningと同じぐらいの精度\">FTGDは全勾配のfine-tuningと同じぐらいの精度\u003C/h3>\n\u003Cul>\n\u003Cli>各タスクの精度は保ったまま、Perplexityの増加を抑制\u003C/li>\n\u003Cli>目的タスクの改善のみが行えていそう\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"タスク空間は語彙ではなく言語構造でクラスタ化\">タスク空間は語彙ではなく言語構造でクラスタ化\u003C/h3>\n\u003Cul>\n\u003Cli>より抽象的な言語概念を共有パラメータとしてる説\u003C/li>\n\u003Cli>モデル規模が大きいほどより抽象概念を一般化\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"感想\">感想\u003C/h2>\n\u003Cul>\n\u003Cli>単純に語彙が似てるからではなく、文法的な現象に着目しているのは興味深い\u003C/li>\n\u003Cli>言語分野のタスクのみに着目していたので、汎用的なタスク空間みたいなのをつくれたらおもしろそう\u003C/li>\n\u003C/ul>",{"headings":177,"localImagePaths":195,"remoteImagePaths":196,"frontmatter":197,"imagePaths":198},[178,179,180,181,184,187,189,192,194],{"depth":24,"slug":89,"text":90},{"depth":24,"slug":25,"text":25},{"depth":24,"slug":30,"text":30},{"depth":24,"slug":182,"text":183},"ftgd","FTGD",{"depth":24,"slug":185,"text":186},"similarity-probing","Similarity Probing",{"depth":24,"slug":188,"text":188},"結果",{"depth":35,"slug":190,"text":191},"ftgdは全勾配のfine-tuningと同じぐらいの精度","FTGDは全勾配のfine-tuningと同じぐらいの精度",{"depth":35,"slug":193,"text":193},"タスク空間は語彙ではなく言語構造でクラスタ化",{"depth":24,"slug":70,"text":70},[],[],{"title":169,"date":170},[],"Interpretability of Language Models via Task Spaces.md","text-to-lora-instant-transformer-adaption",{"id":200,"data":202,"body":205,"filePath":206,"digest":207,"rendered":208,"legacyId":239},{"title":203,"date":204},"Text-to-LoRA: Instant Transformer Adaption (2025)","2025-06-19","## arXiv\nhttps://arxiv.org/abs/2506.06105\n\n## 著者\n[Rujikorn Charakorn](https://arxiv.org/search/cs?searchtype=author&query=Charakorn,+R), [Edoardo Cetin](https://arxiv.org/search/cs?searchtype=author&query=Cetin,+E), [Yujin Tang](https://arxiv.org/search/cs?searchtype=author&query=Tang,+Y), [Robert Tjarko Lange](https://arxiv.org/search/cs?searchtype=author&query=Lange,+R+T)\n\n## 要約\n- 基盤モデルは汎用的でタスク固有の適応が必要\n\t- 従来はデータセットを使ってファインチューニングしていた\n\t- 時間とお金がかかるしハイパラ設定に依存\n- Text-to-LoRA(T2L)\n\t- 自然言語によるタスクの説明から単一の前向き計算だけでLoRAアダプタを生成\n- 事前学習済みのLoRAアダプタでT2Lを訓練\n\t- 固有アダプタと同等の性能\n\t- 全く未知のタスクにもゼロショットで一般化\n- 基盤モデルのタスク適応を民主化する第一歩\n\n## 用語\n### LoRA\n- 重み分割したやつ\n### Hypernetworks\n- 別のニューラルネットワークのパラメータを生成するネットワーク\n$$\nW_l = h_\\theta (\\phi_l)\n$$\n- $\\theta$: Hypernetworkのパラメータ\n- $\\phi_l$: 生成したい層$l$に関する記述(どの層の重みを生成するかの指示ベクトルてきな)\n- $W_l$: ベースネットの第$l$層の重み\n\n## T2Lアーキテクチャ\n$$\n\\Delta W_{m,l}^{(i)} \\;=\\; h_{\\theta}\\!\\bigl(\\operatorname{concat}\\bigl[f(z_{i}),\\,E[m],\\,E[l]\\bigr]\\bigr)\n$$\n- $f(z_i)$: タスク記述, $E[m]$: モジュール埋め込み, $E[l]$: 層埋め込み\n\n## ざっくり学習について\n### LoRA再構成学習\n- 正解LoRAと同じようなものを生成するようにL1誤差で学習\n- 圧縮できて軽くて速い\n- ゼロショットには弱い\n\n### 下流タスクで直接SFT\n- 入力→LoRA生成→タスク解く→ロス計算→学習\n- 重いけど未知タスクにも強い\n\n## 感想\n- 論文の表を見る限りだと個別タスクごとのLoRAとほんとに同じ性能がでていてびっくり。未来を感じる。\n- 各ベンチマークの詳細を調べてないからなんとも言えないかも(時間がない)\n- 今度ベンチマークまとめ的な記事を作ってみようかなとも思ったり\n- ゼロショット性能はちょっと弱いらしい\n- Accepted at ICML 2025←ガチじゃん","src/content/papers/Text-to-LoRA Instant Transformer Adaption.md","2a398f23dd811929",{"html":209,"metadata":210},"\u003Ch2 id=\"arxiv\">arXiv\u003C/h2>\n\u003Cp>\u003Ca href=\"https://arxiv.org/abs/2506.06105\">https://arxiv.org/abs/2506.06105\u003C/a>\u003C/p>\n\u003Ch2 id=\"著者\">著者\u003C/h2>\n\u003Cp>\u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Charakorn,+R\">Rujikorn Charakorn\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Cetin,+E\">Edoardo Cetin\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Tang,+Y\">Yujin Tang\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Lange,+R+T\">Robert Tjarko Lange\u003C/a>\u003C/p>\n\u003Ch2 id=\"要約\">要約\u003C/h2>\n\u003Cul>\n\u003Cli>基盤モデルは汎用的でタスク固有の適応が必要\n\u003Cul>\n\u003Cli>従来はデータセットを使ってファインチューニングしていた\u003C/li>\n\u003Cli>時間とお金がかかるしハイパラ設定に依存\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>Text-to-LoRA(T2L)\n\u003Cul>\n\u003Cli>自然言語によるタスクの説明から単一の前向き計算だけでLoRAアダプタを生成\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>事前学習済みのLoRAアダプタでT2Lを訓練\n\u003Cul>\n\u003Cli>固有アダプタと同等の性能\u003C/li>\n\u003Cli>全く未知のタスクにもゼロショットで一般化\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>基盤モデルのタスク適応を民主化する第一歩\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"用語\">用語\u003C/h2>\n\u003Ch3 id=\"lora\">LoRA\u003C/h3>\n\u003Cul>\n\u003Cli>重み分割したやつ\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"hypernetworks\">Hypernetworks\u003C/h3>\n\u003Cul>\n\u003Cli>別のニューラルネットワークのパラメータを生成するネットワーク\u003C/li>\n\u003C/ul>\n\u003Cspan class=\"katex-display\">\u003Cspan class=\"katex\">\u003Cspan class=\"katex-mathml\">\u003Cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\u003Csemantics>\u003Cmrow>\u003Cmsub>\u003Cmi>W\u003C/mi>\u003Cmi>l\u003C/mi>\u003C/msub>\u003Cmo>=\u003C/mo>\u003Cmsub>\u003Cmi>h\u003C/mi>\u003Cmi>θ\u003C/mi>\u003C/msub>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmsub>\u003Cmi>ϕ\u003C/mi>\u003Cmi>l\u003C/mi>\u003C/msub>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003Cannotation encoding=\"application/x-tex\">W_l = h_\\theta (\\phi_l)\u003C/annotation>\u003C/semantics>\u003C/math>\u003C/span>\u003Cspan class=\"katex-html\" aria-hidden=\"true\">\u003Cspan class=\"base\">\u003Cspan class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\">\u003C/span>\u003Cspan class=\"mord\">\u003Cspan class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W\u003C/span>\u003Cspan class=\"msupsub\">\u003Cspan class=\"vlist-t vlist-t2\">\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.3361em;\">\u003Cspan style=\"top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;\">\u003Cspan class=\"pstrut\" style=\"height:2.7em;\">\u003C/span>\u003Cspan class=\"sizing reset-size6 size3 mtight\">\u003Cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"vlist-s\">​\u003C/span>\u003C/span>\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.15em;\">\u003Cspan>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"mspace\" style=\"margin-right:0.2778em;\">\u003C/span>\u003Cspan class=\"mrel\">=\u003C/span>\u003Cspan class=\"mspace\" style=\"margin-right:0.2778em;\">\u003C/span>\u003C/span>\u003Cspan class=\"base\">\u003Cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\">\u003C/span>\u003Cspan class=\"mord\">\u003Cspan class=\"mord mathnormal\">h\u003C/span>\u003Cspan class=\"msupsub\">\u003Cspan class=\"vlist-t vlist-t2\">\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.3361em;\">\u003Cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\">\u003Cspan class=\"pstrut\" style=\"height:2.7em;\">\u003C/span>\u003Cspan class=\"sizing reset-size6 size3 mtight\">\u003Cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"vlist-s\">​\u003C/span>\u003C/span>\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.15em;\">\u003Cspan>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"mopen\">(\u003C/span>\u003Cspan class=\"mord\">\u003Cspan class=\"mord mathnormal\">ϕ\u003C/span>\u003Cspan class=\"msupsub\">\u003Cspan class=\"vlist-t vlist-t2\">\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.3361em;\">\u003Cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\">\u003Cspan class=\"pstrut\" style=\"height:2.7em;\">\u003C/span>\u003Cspan class=\"sizing reset-size6 size3 mtight\">\u003Cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"vlist-s\">​\u003C/span>\u003C/span>\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.15em;\">\u003Cspan>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"mclose\">)\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\n\u003Cul>\n\u003Cli>\u003Cspan class=\"katex\">\u003Cspan class=\"katex-mathml\">\u003Cmath xmlns=\"http://www.w3.org/1998/Math/MathML\">\u003Csemantics>\u003Cmrow>\u003Cmi>θ\u003C/mi>\u003C/mrow>\u003Cannotation encoding=\"application/x-tex\">\\theta\u003C/annotation>\u003C/semantics>\u003C/math>\u003C/span>\u003Cspan class=\"katex-html\" aria-hidden=\"true\">\u003Cspan class=\"base\">\u003Cspan class=\"strut\" style=\"height:0.6944em;\">\u003C/span>\u003Cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ\u003C/span>\u003C/span>\u003C/span>\u003C/span>: Hypernetworkのパラメータ\u003C/li>\n\u003Cli>\u003Cspan class=\"katex\">\u003Cspan class=\"katex-mathml\">\u003Cmath xmlns=\"http://www.w3.org/1998/Math/MathML\">\u003Csemantics>\u003Cmrow>\u003Cmsub>\u003Cmi>ϕ\u003C/mi>\u003Cmi>l\u003C/mi>\u003C/msub>\u003C/mrow>\u003Cannotation encoding=\"application/x-tex\">\\phi_l\u003C/annotation>\u003C/semantics>\u003C/math>\u003C/span>\u003Cspan class=\"katex-html\" aria-hidden=\"true\">\u003Cspan class=\"base\">\u003Cspan class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\">\u003C/span>\u003Cspan class=\"mord\">\u003Cspan class=\"mord mathnormal\">ϕ\u003C/span>\u003Cspan class=\"msupsub\">\u003Cspan class=\"vlist-t vlist-t2\">\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.3361em;\">\u003Cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\">\u003Cspan class=\"pstrut\" style=\"height:2.7em;\">\u003C/span>\u003Cspan class=\"sizing reset-size6 size3 mtight\">\u003Cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"vlist-s\">​\u003C/span>\u003C/span>\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.15em;\">\u003Cspan>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>: 生成したい層\u003Cspan class=\"katex\">\u003Cspan class=\"katex-mathml\">\u003Cmath xmlns=\"http://www.w3.org/1998/Math/MathML\">\u003Csemantics>\u003Cmrow>\u003Cmi>l\u003C/mi>\u003C/mrow>\u003Cannotation encoding=\"application/x-tex\">l\u003C/annotation>\u003C/semantics>\u003C/math>\u003C/span>\u003Cspan class=\"katex-html\" aria-hidden=\"true\">\u003Cspan class=\"base\">\u003Cspan class=\"strut\" style=\"height:0.6944em;\">\u003C/span>\u003Cspan class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l\u003C/span>\u003C/span>\u003C/span>\u003C/span>に関する記述(どの層の重みを生成するかの指示ベクトルてきな)\u003C/li>\n\u003Cli>\u003Cspan class=\"katex\">\u003Cspan class=\"katex-mathml\">\u003Cmath xmlns=\"http://www.w3.org/1998/Math/MathML\">\u003Csemantics>\u003Cmrow>\u003Cmsub>\u003Cmi>W\u003C/mi>\u003Cmi>l\u003C/mi>\u003C/msub>\u003C/mrow>\u003Cannotation encoding=\"application/x-tex\">W_l\u003C/annotation>\u003C/semantics>\u003C/math>\u003C/span>\u003Cspan class=\"katex-html\" aria-hidden=\"true\">\u003Cspan class=\"base\">\u003Cspan class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\">\u003C/span>\u003Cspan class=\"mord\">\u003Cspan class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W\u003C/span>\u003Cspan class=\"msupsub\">\u003Cspan class=\"vlist-t vlist-t2\">\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.3361em;\">\u003Cspan style=\"top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;\">\u003Cspan class=\"pstrut\" style=\"height:2.7em;\">\u003C/span>\u003Cspan class=\"sizing reset-size6 size3 mtight\">\u003Cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"vlist-s\">​\u003C/span>\u003C/span>\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.15em;\">\u003Cspan>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>: ベースネットの第\u003Cspan class=\"katex\">\u003Cspan class=\"katex-mathml\">\u003Cmath xmlns=\"http://www.w3.org/1998/Math/MathML\">\u003Csemantics>\u003Cmrow>\u003Cmi>l\u003C/mi>\u003C/mrow>\u003Cannotation encoding=\"application/x-tex\">l\u003C/annotation>\u003C/semantics>\u003C/math>\u003C/span>\u003Cspan class=\"katex-html\" aria-hidden=\"true\">\u003Cspan class=\"base\">\u003Cspan class=\"strut\" style=\"height:0.6944em;\">\u003C/span>\u003Cspan class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l\u003C/span>\u003C/span>\u003C/span>\u003C/span>層の重み\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"t2lアーキテクチャ\">T2Lアーキテクチャ\u003C/h2>\n\u003Cspan class=\"katex-display\">\u003Cspan class=\"katex\">\u003Cspan class=\"katex-mathml\">\u003Cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\u003Csemantics>\u003Cmrow>\u003Cmi mathvariant=\"normal\">Δ\u003C/mi>\u003Cmsubsup>\u003Cmi>W\u003C/mi>\u003Cmrow>\u003Cmi>m\u003C/mi>\u003Cmo separator=\"true\">,\u003C/mo>\u003Cmi>l\u003C/mi>\u003C/mrow>\u003Cmrow>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmi>i\u003C/mi>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003C/msubsup>\u003Cmtext>  \u003C/mtext>\u003Cmo>=\u003C/mo>\u003Cmtext>  \u003C/mtext>\u003Cmsub>\u003Cmi>h\u003C/mi>\u003Cmi>θ\u003C/mi>\u003C/msub>\u003Cmtext> ⁣\u003C/mtext>\u003Cmo fence=\"true\" stretchy=\"true\" minsize=\"1.2em\" maxsize=\"1.2em\">(\u003C/mo>\u003Cmi mathvariant=\"normal\">concat\u003C/mi>\u003Cmo>⁡\u003C/mo>\u003Cmo fence=\"true\" stretchy=\"true\" minsize=\"1.2em\" maxsize=\"1.2em\">[\u003C/mo>\u003Cmi>f\u003C/mi>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmsub>\u003Cmi>z\u003C/mi>\u003Cmi>i\u003C/mi>\u003C/msub>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003Cmo separator=\"true\">,\u003C/mo>\u003Cmtext> \u003C/mtext>\u003Cmi>E\u003C/mi>\u003Cmo stretchy=\"false\">[\u003C/mo>\u003Cmi>m\u003C/mi>\u003Cmo stretchy=\"false\">]\u003C/mo>\u003Cmo separator=\"true\">,\u003C/mo>\u003Cmtext> \u003C/mtext>\u003Cmi>E\u003C/mi>\u003Cmo stretchy=\"false\">[\u003C/mo>\u003Cmi>l\u003C/mi>\u003Cmo stretchy=\"false\">]\u003C/mo>\u003Cmo fence=\"true\" stretchy=\"true\" minsize=\"1.2em\" maxsize=\"1.2em\">]\u003C/mo>\u003Cmo fence=\"true\" stretchy=\"true\" minsize=\"1.2em\" maxsize=\"1.2em\">)\u003C/mo>\u003C/mrow>\u003Cannotation encoding=\"application/x-tex\">\\Delta W_{m,l}^{(i)} \\;=\\; h_{\\theta}\\!\\bigl(\\operatorname{concat}\\bigl[f(z_{i}),\\,E[m],\\,E[l]\\bigr]\\bigr)\u003C/annotation>\u003C/semantics>\u003C/math>\u003C/span>\u003Cspan class=\"katex-html\" aria-hidden=\"true\">\u003Cspan class=\"base\">\u003Cspan class=\"strut\" style=\"height:1.4822em;vertical-align:-0.4374em;\">\u003C/span>\u003Cspan class=\"mord\">Δ\u003C/span>\u003Cspan class=\"mord\">\u003Cspan class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W\u003C/span>\u003Cspan class=\"msupsub\">\u003Cspan class=\"vlist-t vlist-t2\">\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:1.0448em;\">\u003Cspan style=\"top:-2.3987em;margin-left:-0.1389em;margin-right:0.05em;\">\u003Cspan class=\"pstrut\" style=\"height:2.7em;\">\u003C/span>\u003Cspan class=\"sizing reset-size6 size3 mtight\">\u003Cspan class=\"mord mtight\">\u003Cspan class=\"mord mathnormal mtight\">m\u003C/span>\u003Cspan class=\"mpunct mtight\">,\u003C/span>\u003Cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan style=\"top:-3.2198em;margin-right:0.05em;\">\u003Cspan class=\"pstrut\" style=\"height:2.7em;\">\u003C/span>\u003Cspan class=\"sizing reset-size6 size3 mtight\">\u003Cspan class=\"mord mtight\">\u003Cspan class=\"mopen mtight\">(\u003C/span>\u003Cspan class=\"mord mathnormal mtight\">i\u003C/span>\u003Cspan class=\"mclose mtight\">)\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"vlist-s\">​\u003C/span>\u003C/span>\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.4374em;\">\u003Cspan>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"mspace\" style=\"margin-right:0.2778em;\">\u003C/span>\u003Cspan class=\"mspace\" style=\"margin-right:0.2778em;\">\u003C/span>\u003Cspan class=\"mrel\">=\u003C/span>\u003Cspan class=\"mspace\" style=\"margin-right:0.2778em;\">\u003C/span>\u003Cspan class=\"mspace\" style=\"margin-right:0.2778em;\">\u003C/span>\u003C/span>\u003Cspan class=\"base\">\u003Cspan class=\"strut\" style=\"height:1.2em;vertical-align:-0.35em;\">\u003C/span>\u003Cspan class=\"mord\">\u003Cspan class=\"mord mathnormal\">h\u003C/span>\u003Cspan class=\"msupsub\">\u003Cspan class=\"vlist-t vlist-t2\">\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.3361em;\">\u003Cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\">\u003Cspan class=\"pstrut\" style=\"height:2.7em;\">\u003C/span>\u003Cspan class=\"sizing reset-size6 size3 mtight\">\u003Cspan class=\"mord mtight\">\u003Cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"vlist-s\">​\u003C/span>\u003C/span>\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.15em;\">\u003Cspan>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"mspace\" style=\"margin-right:-0.1667em;\">\u003C/span>\u003Cspan class=\"mopen\">\u003Cspan class=\"delimsizing size1\">(\u003C/span>\u003C/span>\u003Cspan class=\"mop\">\u003Cspan class=\"mord mathrm\">concat\u003C/span>\u003C/span>\u003Cspan class=\"mopen\">\u003Cspan class=\"delimsizing size1\">[\u003C/span>\u003C/span>\u003Cspan class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f\u003C/span>\u003Cspan class=\"mopen\">(\u003C/span>\u003Cspan class=\"mord\">\u003Cspan class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z\u003C/span>\u003Cspan class=\"msupsub\">\u003Cspan class=\"vlist-t vlist-t2\">\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.3117em;\">\u003Cspan style=\"top:-2.55em;margin-left:-0.044em;margin-right:0.05em;\">\u003Cspan class=\"pstrut\" style=\"height:2.7em;\">\u003C/span>\u003Cspan class=\"sizing reset-size6 size3 mtight\">\u003Cspan class=\"mord mtight\">\u003Cspan class=\"mord mathnormal mtight\">i\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"vlist-s\">​\u003C/span>\u003C/span>\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.15em;\">\u003Cspan>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"mclose\">)\u003C/span>\u003Cspan class=\"mpunct\">,\u003C/span>\u003Cspan class=\"mspace\" style=\"margin-right:0.1667em;\">\u003C/span>\u003Cspan class=\"mspace\" style=\"margin-right:0.1667em;\">\u003C/span>\u003Cspan class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E\u003C/span>\u003Cspan class=\"mopen\">[\u003C/span>\u003Cspan class=\"mord mathnormal\">m\u003C/span>\u003Cspan class=\"mclose\">]\u003C/span>\u003Cspan class=\"mpunct\">,\u003C/span>\u003Cspan class=\"mspace\" style=\"margin-right:0.1667em;\">\u003C/span>\u003Cspan class=\"mspace\" style=\"margin-right:0.1667em;\">\u003C/span>\u003Cspan class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E\u003C/span>\u003Cspan class=\"mopen\">[\u003C/span>\u003Cspan class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l\u003C/span>\u003Cspan class=\"mclose\">]\u003C/span>\u003Cspan class=\"mclose\">\u003Cspan class=\"delimsizing size1\">]\u003C/span>\u003C/span>\u003Cspan class=\"mclose\">\u003Cspan class=\"delimsizing size1\">)\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\n\u003Cul>\n\u003Cli>\u003Cspan class=\"katex\">\u003Cspan class=\"katex-mathml\">\u003Cmath xmlns=\"http://www.w3.org/1998/Math/MathML\">\u003Csemantics>\u003Cmrow>\u003Cmi>f\u003C/mi>\u003Cmo stretchy=\"false\">(\u003C/mo>\u003Cmsub>\u003Cmi>z\u003C/mi>\u003Cmi>i\u003C/mi>\u003C/msub>\u003Cmo stretchy=\"false\">)\u003C/mo>\u003C/mrow>\u003Cannotation encoding=\"application/x-tex\">f(z_i)\u003C/annotation>\u003C/semantics>\u003C/math>\u003C/span>\u003Cspan class=\"katex-html\" aria-hidden=\"true\">\u003Cspan class=\"base\">\u003Cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\">\u003C/span>\u003Cspan class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f\u003C/span>\u003Cspan class=\"mopen\">(\u003C/span>\u003Cspan class=\"mord\">\u003Cspan class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z\u003C/span>\u003Cspan class=\"msupsub\">\u003Cspan class=\"vlist-t vlist-t2\">\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.3117em;\">\u003Cspan style=\"top:-2.55em;margin-left:-0.044em;margin-right:0.05em;\">\u003Cspan class=\"pstrut\" style=\"height:2.7em;\">\u003C/span>\u003Cspan class=\"sizing reset-size6 size3 mtight\">\u003Cspan class=\"mord mathnormal mtight\">i\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"vlist-s\">​\u003C/span>\u003C/span>\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.15em;\">\u003Cspan>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003Cspan class=\"mclose\">)\u003C/span>\u003C/span>\u003C/span>\u003C/span>: タスク記述, \u003Cspan class=\"katex\">\u003Cspan class=\"katex-mathml\">\u003Cmath xmlns=\"http://www.w3.org/1998/Math/MathML\">\u003Csemantics>\u003Cmrow>\u003Cmi>E\u003C/mi>\u003Cmo stretchy=\"false\">[\u003C/mo>\u003Cmi>m\u003C/mi>\u003Cmo stretchy=\"false\">]\u003C/mo>\u003C/mrow>\u003Cannotation encoding=\"application/x-tex\">E[m]\u003C/annotation>\u003C/semantics>\u003C/math>\u003C/span>\u003Cspan class=\"katex-html\" aria-hidden=\"true\">\u003Cspan class=\"base\">\u003Cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\">\u003C/span>\u003Cspan class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E\u003C/span>\u003Cspan class=\"mopen\">[\u003C/span>\u003Cspan class=\"mord mathnormal\">m\u003C/span>\u003Cspan class=\"mclose\">]\u003C/span>\u003C/span>\u003C/span>\u003C/span>: モジュール埋め込み, \u003Cspan class=\"katex\">\u003Cspan class=\"katex-mathml\">\u003Cmath xmlns=\"http://www.w3.org/1998/Math/MathML\">\u003Csemantics>\u003Cmrow>\u003Cmi>E\u003C/mi>\u003Cmo stretchy=\"false\">[\u003C/mo>\u003Cmi>l\u003C/mi>\u003Cmo stretchy=\"false\">]\u003C/mo>\u003C/mrow>\u003Cannotation encoding=\"application/x-tex\">E[l]\u003C/annotation>\u003C/semantics>\u003C/math>\u003C/span>\u003Cspan class=\"katex-html\" aria-hidden=\"true\">\u003Cspan class=\"base\">\u003Cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\">\u003C/span>\u003Cspan class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E\u003C/span>\u003Cspan class=\"mopen\">[\u003C/span>\u003Cspan class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l\u003C/span>\u003Cspan class=\"mclose\">]\u003C/span>\u003C/span>\u003C/span>\u003C/span>: 層埋め込み\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"ざっくり学習について\">ざっくり学習について\u003C/h2>\n\u003Ch3 id=\"lora再構成学習\">LoRA再構成学習\u003C/h3>\n\u003Cul>\n\u003Cli>正解LoRAと同じようなものを生成するようにL1誤差で学習\u003C/li>\n\u003Cli>圧縮できて軽くて速い\u003C/li>\n\u003Cli>ゼロショットには弱い\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"下流タスクで直接sft\">下流タスクで直接SFT\u003C/h3>\n\u003Cul>\n\u003Cli>入力→LoRA生成→タスク解く→ロス計算→学習\u003C/li>\n\u003Cli>重いけど未知タスクにも強い\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"感想\">感想\u003C/h2>\n\u003Cul>\n\u003Cli>論文の表を見る限りだと個別タスクごとのLoRAとほんとに同じ性能がでていてびっくり。未来を感じる。\u003C/li>\n\u003Cli>各ベンチマークの詳細を調べてないからなんとも言えないかも(時間がない)\u003C/li>\n\u003Cli>今度ベンチマークまとめ的な記事を作ってみようかなとも思ったり\u003C/li>\n\u003Cli>ゼロショット性能はちょっと弱いらしい\u003C/li>\n\u003Cli>Accepted at ICML 2025←ガチじゃん\u003C/li>\n\u003C/ul>",{"headings":211,"localImagePaths":235,"remoteImagePaths":236,"frontmatter":237,"imagePaths":238},[212,213,214,215,217,220,223,226,228,231,234],{"depth":24,"slug":89,"text":90},{"depth":24,"slug":25,"text":25},{"depth":24,"slug":30,"text":30},{"depth":24,"slug":216,"text":216},"用語",{"depth":35,"slug":218,"text":219},"lora","LoRA",{"depth":35,"slug":221,"text":222},"hypernetworks","Hypernetworks",{"depth":24,"slug":224,"text":225},"t2lアーキテクチャ","T2Lアーキテクチャ",{"depth":24,"slug":227,"text":227},"ざっくり学習について",{"depth":35,"slug":229,"text":230},"lora再構成学習","LoRA再構成学習",{"depth":35,"slug":232,"text":233},"下流タスクで直接sft","下流タスクで直接SFT",{"depth":24,"slug":70,"text":70},[],[],{"title":203,"date":204},[],"Text-to-LoRA Instant Transformer Adaption.md","the-illusion-of-thinking_--understanding-the-strengths-and-limitations-of-reasoning-models--via-the-lens-of-problem-complexity",{"id":240,"data":242,"body":245,"filePath":246,"digest":247,"rendered":248,"legacyId":278},{"title":243,"date":244},"The Illusion of Thinking:  Understanding the Strengths and Limitations of Reasoning Models  via the Lens of Problem Complexity (2025)","2025-06-10","## 論文ページ\nhttps://ml-site.cdn-apple.com/papers/the-illusion-of-thinking.pdf\n\n## 著者\nParshin Shojaee, Iman Mirzadeh,  Keivan Alizadeh, Maxwell Horton, Samy Bengio, Mehrdad Farajtabar\n\n## 要約\n- リーズニングモデル(LRM)が問題が複雑になるとどのような挙動を示すか\n\t- 低複雑度: 標準的なLLMがLRMを上回る\n\t- 中複雑度: LRMが優位に立つ\n\t- 高複雑度: 両方のモデルが機能しなくなる(Accuracyがほぼゼロ)\n- LRMは単純な問題には考えすぎるし、複雑な問題は完全に放棄する\n\n## 問題の複雑さをどう制御するか\n- 4つのパズル\n\t- Tower of Hanoi\n\t- Checker Jumping\n\t- River Crossing\n\t- Blocks World\n- 問題のサイズ$N$を変更して制御\n\n## タスクの複雑さによる挙動\n### 低複雑度\n- リーズニングじゃない方が性能もいいしトークン消費も少ない\n### 中複雑度\n- LRMが優位に\n### 高複雑度\n- ある複雑度の閾値を超えると両モデルで正解率がゼロに\n- 性能の崩壊\n\n## 複雑なタスクにおけるLRMの思考放棄\n- 問題が複雑になるとより多くのトークンを思考に費やすようになる\n- 性能が崩壊する臨界点に近づくと、逆に思考に費やすトークンが減少\n\t- まだトークン上限に達しそうになくてもしこうするのをやめちゃう\n\t- LRMの推論能力に根本的な限界\n\n## 真の推論能力を持っているのか\n- Tower of Hanoiにおいて、解法となるアルゴリズムをプロンプトで与えても、臨界点(正解率がゼロになる複雑度)がほぼ変化しなかった。\n- モデルが論理的なアルゴリズムを忠実に実行するのに限界がある\n\n## パズル間での推論能力の差\n- Tower of Hanoiでは31手必要でも解ける\n- River Crossingは11手でも解けない\n- 学習データにハノイがいっぱいあってそこでみた解法をトレースしてるだけでは？\n\n## 感想\n- リーズニングモデルの現在の枠組みでの限界を感じた\n- 人間の思考が及ばないところまで考えてほしいのに途中で放棄されてしまうと、シンギュラリティ的なものが期待できなくなってしまいそう\n- サボり癖まで学習してるとかだったらむしろ面白いかも","src/content/papers/The Illusion of Thinking_  Understanding the Strengths and Limitations of Reasoning Models  via the Lens of Problem Complexity.md","9dc8046cffd7cec9",{"html":249,"metadata":250},"\u003Ch2 id=\"論文ページ\">論文ページ\u003C/h2>\n\u003Cp>\u003Ca href=\"https://ml-site.cdn-apple.com/papers/the-illusion-of-thinking.pdf\">https://ml-site.cdn-apple.com/papers/the-illusion-of-thinking.pdf\u003C/a>\u003C/p>\n\u003Ch2 id=\"著者\">著者\u003C/h2>\n\u003Cp>Parshin Shojaee, Iman Mirzadeh,  Keivan Alizadeh, Maxwell Horton, Samy Bengio, Mehrdad Farajtabar\u003C/p>\n\u003Ch2 id=\"要約\">要約\u003C/h2>\n\u003Cul>\n\u003Cli>リーズニングモデル(LRM)が問題が複雑になるとどのような挙動を示すか\n\u003Cul>\n\u003Cli>低複雑度: 標準的なLLMがLRMを上回る\u003C/li>\n\u003Cli>中複雑度: LRMが優位に立つ\u003C/li>\n\u003Cli>高複雑度: 両方のモデルが機能しなくなる(Accuracyがほぼゼロ)\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>LRMは単純な問題には考えすぎるし、複雑な問題は完全に放棄する\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"問題の複雑さをどう制御するか\">問題の複雑さをどう制御するか\u003C/h2>\n\u003Cul>\n\u003Cli>4つのパズル\n\u003Cul>\n\u003Cli>Tower of Hanoi\u003C/li>\n\u003Cli>Checker Jumping\u003C/li>\n\u003Cli>River Crossing\u003C/li>\n\u003Cli>Blocks World\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>問題のサイズ\u003Cspan class=\"katex\">\u003Cspan class=\"katex-mathml\">\u003Cmath xmlns=\"http://www.w3.org/1998/Math/MathML\">\u003Csemantics>\u003Cmrow>\u003Cmi>N\u003C/mi>\u003C/mrow>\u003Cannotation encoding=\"application/x-tex\">N\u003C/annotation>\u003C/semantics>\u003C/math>\u003C/span>\u003Cspan class=\"katex-html\" aria-hidden=\"true\">\u003Cspan class=\"base\">\u003Cspan class=\"strut\" style=\"height:0.6833em;\">\u003C/span>\u003Cspan class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N\u003C/span>\u003C/span>\u003C/span>\u003C/span>を変更して制御\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"タスクの複雑さによる挙動\">タスクの複雑さによる挙動\u003C/h2>\n\u003Ch3 id=\"低複雑度\">低複雑度\u003C/h3>\n\u003Cul>\n\u003Cli>リーズニングじゃない方が性能もいいしトークン消費も少ない\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"中複雑度\">中複雑度\u003C/h3>\n\u003Cul>\n\u003Cli>LRMが優位に\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"高複雑度\">高複雑度\u003C/h3>\n\u003Cul>\n\u003Cli>ある複雑度の閾値を超えると両モデルで正解率がゼロに\u003C/li>\n\u003Cli>性能の崩壊\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"複雑なタスクにおけるlrmの思考放棄\">複雑なタスクにおけるLRMの思考放棄\u003C/h2>\n\u003Cul>\n\u003Cli>問題が複雑になるとより多くのトークンを思考に費やすようになる\u003C/li>\n\u003Cli>性能が崩壊する臨界点に近づくと、逆に思考に費やすトークンが減少\n\u003Cul>\n\u003Cli>まだトークン上限に達しそうになくてもしこうするのをやめちゃう\u003C/li>\n\u003Cli>LRMの推論能力に根本的な限界\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"真の推論能力を持っているのか\">真の推論能力を持っているのか\u003C/h2>\n\u003Cul>\n\u003Cli>Tower of Hanoiにおいて、解法となるアルゴリズムをプロンプトで与えても、臨界点(正解率がゼロになる複雑度)がほぼ変化しなかった。\u003C/li>\n\u003Cli>モデルが論理的なアルゴリズムを忠実に実行するのに限界がある\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"パズル間での推論能力の差\">パズル間での推論能力の差\u003C/h2>\n\u003Cul>\n\u003Cli>Tower of Hanoiでは31手必要でも解ける\u003C/li>\n\u003Cli>River Crossingは11手でも解けない\u003C/li>\n\u003Cli>学習データにハノイがいっぱいあってそこでみた解法をトレースしてるだけでは？\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"感想\">感想\u003C/h2>\n\u003Cul>\n\u003Cli>リーズニングモデルの現在の枠組みでの限界を感じた\u003C/li>\n\u003Cli>人間の思考が及ばないところまで考えてほしいのに途中で放棄されてしまうと、シンギュラリティ的なものが期待できなくなってしまいそう\u003C/li>\n\u003Cli>サボり癖まで学習してるとかだったらむしろ面白いかも\u003C/li>\n\u003C/ul>",{"headings":251,"localImagePaths":274,"remoteImagePaths":275,"frontmatter":276,"imagePaths":277},[252,254,255,256,258,260,262,264,266,269,271,273],{"depth":24,"slug":253,"text":253},"論文ページ",{"depth":24,"slug":25,"text":25},{"depth":24,"slug":30,"text":30},{"depth":24,"slug":257,"text":257},"問題の複雑さをどう制御するか",{"depth":24,"slug":259,"text":259},"タスクの複雑さによる挙動",{"depth":35,"slug":261,"text":261},"低複雑度",{"depth":35,"slug":263,"text":263},"中複雑度",{"depth":35,"slug":265,"text":265},"高複雑度",{"depth":24,"slug":267,"text":268},"複雑なタスクにおけるlrmの思考放棄","複雑なタスクにおけるLRMの思考放棄",{"depth":24,"slug":270,"text":270},"真の推論能力を持っているのか",{"depth":24,"slug":272,"text":272},"パズル間での推論能力の差",{"depth":24,"slug":70,"text":70},[],[],{"title":243,"date":244},[],"The Illusion of Thinking_  Understanding the Strengths and Limitations of Reasoning Models  via the Lens of Problem Complexity.md","do-music-generation-models-encode-music-theory",{"id":279,"data":281,"body":284,"filePath":285,"digest":286,"rendered":287,"legacyId":324},{"title":282,"date":283},"Do Music Generation Models Encode Music Theory?","2025-06-28","## arXiv\nhttps://arxiv.org/abs/2410.00872\n\n## 著者\n[Megan Wei](https://arxiv.org/search/cs?searchtype=author&query=Wei,+M), [Michael Freeman](https://arxiv.org/search/cs?searchtype=author&query=Freeman,+M), [Chris Donahue](https://arxiv.org/search/cs?searchtype=author&query=Donahue,+C), [Chen Sun](https://arxiv.org/search/cs?searchtype=author&query=Sun,+C)\n\n##  ざっくり\n- 音楽生成モデルが音楽理論をエンコードしてるのかを、概念ごと(コード、テンポ、スケールとか)にデータセットを用意して確認しよう\n\t- エンコードしている = probe modelが内部表現から音楽理論の概念をデコードできる\n- SynTheory\n\t- データセット\n\t- Tempo(テンポ), Time Signature(拍子), Notes(音符？音階？), Intervals(インターバル), Scales(スケール), Chords(コード), Chord Progressions(コード進行)の7つそれぞれ\n- 結果\n\t- 人手の特徴量よりprobe modelのスコアが高い\n\t- エンコードできてるっぽい\n\n## models & features\n### Jukebox\n- 音楽生成モデル\n- VQ-VAEモデルとTransformer decoder で構成\n- 音声波形を離散的なコードに符号化して、decoderがコード化された音声を出力\n### MusicGen\n- 音楽生成モデル\n- 事前学習済みの畳み込みオートエンコーダー(EnCodec)、事前学習済みT5テキストエンコーダー(未使用)、音響トランスフォーマーデコーダーからなる\n- MusicGen Audio Codec\n\t- EnCodec部分\n\t- 音声を再構築する役割\n- MusicGen Decoder LM(S,M,L)\n\t- 音響トランスフォーマーデコーダー部分\n\n### Features\n- Mel Spectrogram\n- MFCC\n- Constant-Q Chromagram\n- Aggregate Hand-crafted (上の三つ合わせたもの)\n\n## probe model\n- 線形と2-layerのMLP(512 hidden, ReLU)\n- 目的関数\n\t- Tempo: MSE回帰, 指標 $R^2$\n\t- Others: Cross-Entropy, 指標 Accuracy\n- データは70/15/15でスプリット\n- probeの精度でその層のベクトルにそれだけ音楽的概念が表れているかを測る\n\n## SynTheory\n- 完全合成かつ著作権フリー\n- 音楽理論の7概念を1つずつ切り出し、概念の混ざりを解消\n### リズム系\n- Tempo\n- Time Signature\n- クリック音とリバーブ差分\n### 調性系\n- Notes\n- Intervals\n- Scales\n- Chords\n- Chord Progressions\n- すべて4拍子, BPM120、ピッチ関連のみ変化\n\n### 結果\n![img|500](https://i.gyazo.com/6af93cb5155e7a6bc3778cd320236c75.png)\n- y軸は各概念の評価の平均\n\n![img](https://i.gyazo.com/6b949f9a565d799c684344cf30a4b78d.png)\n- 各モデル/特徴量の概念ごとのprobe結果(最高スコアの1層を採用)\n- Jukebox LMが一番いい\n\t- 上のグラフだと最後下がっているのが気になるところ\n- MusicGenはなぜかサイズが小さい方がAverageが高い\n\t- 詳細分析はなかった\n\n## 結論\n- モデルは音楽理論をエンコードしてるっぽい\n- 特徴量よりもいい感じにエンコードしてるっぽい\n\n## 感想\n- 論文に音楽の用語が出てくるだけで興奮できる\n- probing scoreの最高スコアの層を採用しているのが、最終的な出力と関係ない感じがして疑問\n- 音楽関連のベンチマークとかモデルとかにも詳しくなっていきたい","src/content/papers/Do Music Generation Models Encode Music Theory.md","4b25d95fa0352d16",{"html":288,"metadata":289},"\u003Ch2 id=\"arxiv\">arXiv\u003C/h2>\n\u003Cp>\u003Ca href=\"https://arxiv.org/abs/2410.00872\">https://arxiv.org/abs/2410.00872\u003C/a>\u003C/p>\n\u003Ch2 id=\"著者\">著者\u003C/h2>\n\u003Cp>\u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Wei,+M\">Megan Wei\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Freeman,+M\">Michael Freeman\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Donahue,+C\">Chris Donahue\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Sun,+C\">Chen Sun\u003C/a>\u003C/p>\n\u003Ch2 id=\"ざっくり\">ざっくり\u003C/h2>\n\u003Cul>\n\u003Cli>音楽生成モデルが音楽理論をエンコードしてるのかを、概念ごと(コード、テンポ、スケールとか)にデータセットを用意して確認しよう\n\u003Cul>\n\u003Cli>エンコードしている = probe modelが内部表現から音楽理論の概念をデコードできる\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>SynTheory\n\u003Cul>\n\u003Cli>データセット\u003C/li>\n\u003Cli>Tempo(テンポ), Time Signature(拍子), Notes(音符？音階？), Intervals(インターバル), Scales(スケール), Chords(コード), Chord Progressions(コード進行)の7つそれぞれ\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>結果\n\u003Cul>\n\u003Cli>人手の特徴量よりprobe modelのスコアが高い\u003C/li>\n\u003Cli>エンコードできてるっぽい\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"models--features\">models &#x26; features\u003C/h2>\n\u003Ch3 id=\"jukebox\">Jukebox\u003C/h3>\n\u003Cul>\n\u003Cli>音楽生成モデル\u003C/li>\n\u003Cli>VQ-VAEモデルとTransformer decoder で構成\u003C/li>\n\u003Cli>音声波形を離散的なコードに符号化して、decoderがコード化された音声を出力\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"musicgen\">MusicGen\u003C/h3>\n\u003Cul>\n\u003Cli>音楽生成モデル\u003C/li>\n\u003Cli>事前学習済みの畳み込みオートエンコーダー(EnCodec)、事前学習済みT5テキストエンコーダー(未使用)、音響トランスフォーマーデコーダーからなる\u003C/li>\n\u003Cli>MusicGen Audio Codec\n\u003Cul>\n\u003Cli>EnCodec部分\u003C/li>\n\u003Cli>音声を再構築する役割\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>MusicGen Decoder LM(S,M,L)\n\u003Cul>\n\u003Cli>音響トランスフォーマーデコーダー部分\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"features\">Features\u003C/h3>\n\u003Cul>\n\u003Cli>Mel Spectrogram\u003C/li>\n\u003Cli>MFCC\u003C/li>\n\u003Cli>Constant-Q Chromagram\u003C/li>\n\u003Cli>Aggregate Hand-crafted (上の三つ合わせたもの)\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"probe-model\">probe model\u003C/h2>\n\u003Cul>\n\u003Cli>線形と2-layerのMLP(512 hidden, ReLU)\u003C/li>\n\u003Cli>目的関数\n\u003Cul>\n\u003Cli>Tempo: MSE回帰, 指標 \u003Cspan class=\"katex\">\u003Cspan class=\"katex-mathml\">\u003Cmath xmlns=\"http://www.w3.org/1998/Math/MathML\">\u003Csemantics>\u003Cmrow>\u003Cmsup>\u003Cmi>R\u003C/mi>\u003Cmn>2\u003C/mn>\u003C/msup>\u003C/mrow>\u003Cannotation encoding=\"application/x-tex\">R^2\u003C/annotation>\u003C/semantics>\u003C/math>\u003C/span>\u003Cspan class=\"katex-html\" aria-hidden=\"true\">\u003Cspan class=\"base\">\u003Cspan class=\"strut\" style=\"height:0.8141em;\">\u003C/span>\u003Cspan class=\"mord\">\u003Cspan class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R\u003C/span>\u003Cspan class=\"msupsub\">\u003Cspan class=\"vlist-t\">\u003Cspan class=\"vlist-r\">\u003Cspan class=\"vlist\" style=\"height:0.8141em;\">\u003Cspan style=\"top:-3.063em;margin-right:0.05em;\">\u003Cspan class=\"pstrut\" style=\"height:2.7em;\">\u003C/span>\u003Cspan class=\"sizing reset-size6 size3 mtight\">\u003Cspan class=\"mord mtight\">2\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/span>\u003C/li>\n\u003Cli>Others: Cross-Entropy, 指標 Accuracy\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>データは70/15/15でスプリット\u003C/li>\n\u003Cli>probeの精度でその層のベクトルにそれだけ音楽的概念が表れているかを測る\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"syntheory\">SynTheory\u003C/h2>\n\u003Cul>\n\u003Cli>完全合成かつ著作権フリー\u003C/li>\n\u003Cli>音楽理論の7概念を1つずつ切り出し、概念の混ざりを解消\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"リズム系\">リズム系\u003C/h3>\n\u003Cul>\n\u003Cli>Tempo\u003C/li>\n\u003Cli>Time Signature\u003C/li>\n\u003Cli>クリック音とリバーブ差分\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"調性系\">調性系\u003C/h3>\n\u003Cul>\n\u003Cli>Notes\u003C/li>\n\u003Cli>Intervals\u003C/li>\n\u003Cli>Scales\u003C/li>\n\u003Cli>Chords\u003C/li>\n\u003Cli>Chord Progressions\u003C/li>\n\u003Cli>すべて4拍子, BPM120、ピッチ関連のみ変化\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"結果\">結果\u003C/h3>\n\u003Cp>\u003Cimg src=\"https://i.gyazo.com/6af93cb5155e7a6bc3778cd320236c75.png\" alt=\"img|500\">\u003C/p>\n\u003Cul>\n\u003Cli>y軸は各概念の評価の平均\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cimg src=\"https://i.gyazo.com/6b949f9a565d799c684344cf30a4b78d.png\" alt=\"img\">\u003C/p>\n\u003Cul>\n\u003Cli>各モデル/特徴量の概念ごとのprobe結果(最高スコアの1層を採用)\u003C/li>\n\u003Cli>Jukebox LMが一番いい\n\u003Cul>\n\u003Cli>上のグラフだと最後下がっているのが気になるところ\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>MusicGenはなぜかサイズが小さい方がAverageが高い\n\u003Cul>\n\u003Cli>詳細分析はなかった\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"結論\">結論\u003C/h2>\n\u003Cul>\n\u003Cli>モデルは音楽理論をエンコードしてるっぽい\u003C/li>\n\u003Cli>特徴量よりもいい感じにエンコードしてるっぽい\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"感想\">感想\u003C/h2>\n\u003Cul>\n\u003Cli>論文に音楽の用語が出てくるだけで興奮できる\u003C/li>\n\u003Cli>probing scoreの最高スコアの層を採用しているのが、最終的な出力と関係ない感じがして疑問\u003C/li>\n\u003Cli>音楽関連のベンチマークとかモデルとかにも詳しくなっていきたい\u003C/li>\n\u003C/ul>",{"headings":290,"localImagePaths":320,"remoteImagePaths":321,"frontmatter":322,"imagePaths":323},[291,292,293,295,298,301,304,307,310,313,315,317,318,319],{"depth":24,"slug":89,"text":90},{"depth":24,"slug":25,"text":25},{"depth":24,"slug":294,"text":294},"ざっくり",{"depth":24,"slug":296,"text":297},"models--features","models & features",{"depth":35,"slug":299,"text":300},"jukebox","Jukebox",{"depth":35,"slug":302,"text":303},"musicgen","MusicGen",{"depth":35,"slug":305,"text":306},"features","Features",{"depth":24,"slug":308,"text":309},"probe-model","probe model",{"depth":24,"slug":311,"text":312},"syntheory","SynTheory",{"depth":35,"slug":314,"text":314},"リズム系",{"depth":35,"slug":316,"text":316},"調性系",{"depth":35,"slug":188,"text":188},{"depth":24,"slug":68,"text":68},{"depth":24,"slug":70,"text":70},[],[],{"title":282,"date":283},[],"Do Music Generation Models Encode Music Theory.md"]