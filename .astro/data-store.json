[["Map",1,2,9,10],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.9.0","content-config-digest","6ab83d4c224a4955","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"compressHTML\":true,\"base\":\"/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[],\"experimentalDefaultStyles\":true},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":{\"type\":\"shiki\",\"excludeLangs\":[\"math\"]},\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[],\"rehypePlugins\":[],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"responsiveImages\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false,\"csp\":false},\"legacy\":{\"collections\":false}}","papers",["Map",11,12],"large-language-models-are-human-level-prompt-engineers2023",{"id":11,"data":13,"body":16,"filePath":17,"digest":18,"rendered":19,"legacyId":75},{"title":14,"date":15},"Large Language Models Are Human-Level Prompt Engineers(2023)","2025-06-06","## 著者\n[Yongchao Zhou](https://arxiv.org/search/cs?searchtype=author&query=Zhou,+Y), [Andrei Ioan Muresanu](https://arxiv.org/search/cs?searchtype=author&query=Muresanu,+A+I), [Ziwen Han](https://arxiv.org/search/cs?searchtype=author&query=Han,+Z), [Keiran Paster](https://arxiv.org/search/cs?searchtype=author&query=Paster,+K), [Silviu Pitis](https://arxiv.org/search/cs?searchtype=author&query=Pitis,+S), [Harris Chan](https://arxiv.org/search/cs?searchtype=author&query=Chan,+H), [Jimmy Ba](https://arxiv.org/search/cs?searchtype=author&query=Ba,+J)\n\n## arXivリンク\nhttps://arxiv.org/abs/2211.01910\n\n## 要約\n- プロンプトエンジニアリングを自動化する「Automatic Prompt Engineer (APE)」を提案\n-  ざっくり**LLMにLLMのプロンプトを考えさせる**手法。\n- APEは人間が時間をかけて考えたものと同等かそれ以上の性能を達成\n-  APEのステップ\n\t- LLMに「こういう入力をしたらこういう出力をする」という例を見せて、指示文の候補をいっぱい作らせる\n\t- 候補を試し、その結果をスコアリング\n\t- 最も高いスコアの指示を最良のプロンプトとする\n\n## Abstract\nLLMは汎用的でいいけど「人間が望むことをさせる」のって難しいよね\n→プロンプト大事\n幅広いプロンプトを試す必要があるけどどの指示がどのモデルでいいのかわからない\nLLMを自然言語でプログラムが指定されるブラックボックスなコンピュータとみなそう\n### 提案手法(APE)\nゼロショット学習において24件中24件のInstruction Inductionタスクと21件中17件のBig-Benchタスクで人間レベルの性能を達成\n\n## APEのアルゴリズム(お気持ちベース)\n### \"提案→評価とフィルタリング→選択\"のサイクルを自動化\n### 指示候補の提案\n- LLMにタスクの入出力例を見せ、タスクの遂行用指示文をいっぱい考えさせる。\n- 順方向生成\n\t- 例を先に提示し、最後にこういう指示でしたと続ける\n- 逆方向生成\n\t- \u003Cここに指示を挿入>的な感じで穴埋め問題にして、その後に例を提示\n### 評価・フィルタリング\n指示候補を使って、実際に別のLLMにタスクを解かせ、その性能をスコア付け\n#### 評価基準\n- **実行精度 (Execution accuracy)**: 指示通りにタスクを実行した結果が、想定される正解と一致したかどうかで評価\n- **対数尤度 (Log probability)**: どれだけ正解に近い答えを生成できそうかを確率で評価\n#### フィルタリング\n- 少数の訓練データで候補を評価\n- スコアが良かった上位数パーを残して破棄\n- 残ったものを別の訓練データで再評価\n- これを繰り返して少数の交互に絞る\n#### 選択\n- フィルタリングで残った候補から最も高いスコアのものを採用\n\n## APEを使った結果\n-  ゼロショットで24個のInstruction Inductionタスク全てにおいて、人間が作成したプロンプトと同等かそれ以上の性能を達成\n-  フューショットで24タスク中21タスクで性能が向上するか、同等の結果\n- 高難易度タスク(BIG-Bench)でも17/21で同等かそれ以上\n## いい感じの発見\n### Zero-shot Chain-of-Thought\n- \"Let's think step by step.\"をAPEが改善\n\t- \"Let's work this out in a step by step way to be sure we have the right answer\"のほうがいいらしい\n### TruthfulQA\n- APEがLLMの応答スタイルを制御して「真実性」と「情報提供性」のトレードオフを発見\n\t- 真実性をあげるために嘘をつかせないプロンプト(you have no comment→回答を拒否する選択肢をあたえる)をAPEが見つけた\n\n## 結論\n人間による入力を最小限にしつつ、最適なプロンプトをみつける方法としてAPEは有用\n\n## 感想\n- プロンプト集みたいなのがよくネットに転がってるけどこういうのでちゃんと性能が確認されているのか気になった。\n- 人間が直感的にわかりやすいプロンプトと、LLMがいい性能を示すプロンプトがちょっとちがっておもろい\n- モデル間でも最適なプロンプトがちがって、InstractGPTで最適なプロンプトをGPT-3で用いるとスコアが下がることがあるらしい←自分が使ってるモデルで最適なのを調べる必要あり\n- ↑モデルごと違うならそれこそ自動化とかしないと見つけるの大変そう","src/content/papers/Large Language Models Are Human-Level Prompt Engineers(2023).md","ffd4c9e43e6f75cd",{"html":20,"metadata":21},"\u003Ch2 id=\"著者\">著者\u003C/h2>\n\u003Cp>\u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Zhou,+Y\">Yongchao Zhou\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Muresanu,+A+I\">Andrei Ioan Muresanu\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Han,+Z\">Ziwen Han\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Paster,+K\">Keiran Paster\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Pitis,+S\">Silviu Pitis\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Chan,+H\">Harris Chan\u003C/a>, \u003Ca href=\"https://arxiv.org/search/cs?searchtype=author&#x26;query=Ba,+J\">Jimmy Ba\u003C/a>\u003C/p>\n\u003Ch2 id=\"arxivリンク\">arXivリンク\u003C/h2>\n\u003Cp>\u003Ca href=\"https://arxiv.org/abs/2211.01910\">https://arxiv.org/abs/2211.01910\u003C/a>\u003C/p>\n\u003Ch2 id=\"要約\">要約\u003C/h2>\n\u003Cul>\n\u003Cli>プロンプトエンジニアリングを自動化する「Automatic Prompt Engineer (APE)」を提案\u003C/li>\n\u003Cli>ざっくり\u003Cstrong>LLMにLLMのプロンプトを考えさせる\u003C/strong>手法。\u003C/li>\n\u003Cli>APEは人間が時間をかけて考えたものと同等かそれ以上の性能を達成\u003C/li>\n\u003Cli>APEのステップ\n\u003Cul>\n\u003Cli>LLMに「こういう入力をしたらこういう出力をする」という例を見せて、指示文の候補をいっぱい作らせる\u003C/li>\n\u003Cli>候補を試し、その結果をスコアリング\u003C/li>\n\u003Cli>最も高いスコアの指示を最良のプロンプトとする\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"abstract\">Abstract\u003C/h2>\n\u003Cp>LLMは汎用的でいいけど「人間が望むことをさせる」のって難しいよね\n→プロンプト大事\n幅広いプロンプトを試す必要があるけどどの指示がどのモデルでいいのかわからない\nLLMを自然言語でプログラムが指定されるブラックボックスなコンピュータとみなそう\u003C/p>\n\u003Ch3 id=\"提案手法ape\">提案手法(APE)\u003C/h3>\n\u003Cp>ゼロショット学習において24件中24件のInstruction Inductionタスクと21件中17件のBig-Benchタスクで人間レベルの性能を達成\u003C/p>\n\u003Ch2 id=\"apeのアルゴリズムお気持ちベース\">APEのアルゴリズム(お気持ちベース)\u003C/h2>\n\u003Ch3 id=\"提案評価とフィルタリング選択のサイクルを自動化\">“提案→評価とフィルタリング→選択”のサイクルを自動化\u003C/h3>\n\u003Ch3 id=\"指示候補の提案\">指示候補の提案\u003C/h3>\n\u003Cul>\n\u003Cli>LLMにタスクの入出力例を見せ、タスクの遂行用指示文をいっぱい考えさせる。\u003C/li>\n\u003Cli>順方向生成\n\u003Cul>\n\u003Cli>例を先に提示し、最後にこういう指示でしたと続ける\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>逆方向生成\n\u003Cul>\n\u003Cli>&#x3C;ここに指示を挿入>的な感じで穴埋め問題にして、その後に例を提示\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"評価フィルタリング\">評価・フィルタリング\u003C/h3>\n\u003Cp>指示候補を使って、実際に別のLLMにタスクを解かせ、その性能をスコア付け\u003C/p>\n\u003Ch4 id=\"評価基準\">評価基準\u003C/h4>\n\u003Cul>\n\u003Cli>\u003Cstrong>実行精度 (Execution accuracy)\u003C/strong>: 指示通りにタスクを実行した結果が、想定される正解と一致したかどうかで評価\u003C/li>\n\u003Cli>\u003Cstrong>対数尤度 (Log probability)\u003C/strong>: どれだけ正解に近い答えを生成できそうかを確率で評価\u003C/li>\n\u003C/ul>\n\u003Ch4 id=\"フィルタリング\">フィルタリング\u003C/h4>\n\u003Cul>\n\u003Cli>少数の訓練データで候補を評価\u003C/li>\n\u003Cli>スコアが良かった上位数パーを残して破棄\u003C/li>\n\u003Cli>残ったものを別の訓練データで再評価\u003C/li>\n\u003Cli>これを繰り返して少数の交互に絞る\u003C/li>\n\u003C/ul>\n\u003Ch4 id=\"選択\">選択\u003C/h4>\n\u003Cul>\n\u003Cli>フィルタリングで残った候補から最も高いスコアのものを採用\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"apeを使った結果\">APEを使った結果\u003C/h2>\n\u003Cul>\n\u003Cli>ゼロショットで24個のInstruction Inductionタスク全てにおいて、人間が作成したプロンプトと同等かそれ以上の性能を達成\u003C/li>\n\u003Cli>フューショットで24タスク中21タスクで性能が向上するか、同等の結果\u003C/li>\n\u003Cli>高難易度タスク(BIG-Bench)でも17/21で同等かそれ以上\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"いい感じの発見\">いい感じの発見\u003C/h2>\n\u003Ch3 id=\"zero-shot-chain-of-thought\">Zero-shot Chain-of-Thought\u003C/h3>\n\u003Cul>\n\u003Cli>“Let’s think step by step.”をAPEが改善\n\u003Cul>\n\u003Cli>“Let’s work this out in a step by step way to be sure we have the right answer”のほうがいいらしい\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"truthfulqa\">TruthfulQA\u003C/h3>\n\u003Cul>\n\u003Cli>APEがLLMの応答スタイルを制御して「真実性」と「情報提供性」のトレードオフを発見\n\u003Cul>\n\u003Cli>真実性をあげるために嘘をつかせないプロンプト(you have no comment→回答を拒否する選択肢をあたえる)をAPEが見つけた\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"結論\">結論\u003C/h2>\n\u003Cp>人間による入力を最小限にしつつ、最適なプロンプトをみつける方法としてAPEは有用\u003C/p>\n\u003Ch2 id=\"感想\">感想\u003C/h2>\n\u003Cul>\n\u003Cli>プロンプト集みたいなのがよくネットに転がってるけどこういうのでちゃんと性能が確認されているのか気になった。\u003C/li>\n\u003Cli>人間が直感的にわかりやすいプロンプトと、LLMがいい性能を示すプロンプトがちょっとちがっておもろい\u003C/li>\n\u003Cli>モデル間でも最適なプロンプトがちがって、InstractGPTで最適なプロンプトをGPT-3で用いるとスコアが下がることがあるらしい←自分が使ってるモデルで最適なのを調べる必要あり\u003C/li>\n\u003Cli>↑モデルごと違うならそれこそ自動化とかしないと見つけるの大変そう\u003C/li>\n\u003C/ul>",{"headings":22,"localImagePaths":71,"remoteImagePaths":72,"frontmatter":73,"imagePaths":74},[23,26,29,31,34,38,41,44,46,49,52,54,56,59,61,64,67,69],{"depth":24,"slug":25,"text":25},2,"著者",{"depth":24,"slug":27,"text":28},"arxivリンク","arXivリンク",{"depth":24,"slug":30,"text":30},"要約",{"depth":24,"slug":32,"text":33},"abstract","Abstract",{"depth":35,"slug":36,"text":37},3,"提案手法ape","提案手法(APE)",{"depth":24,"slug":39,"text":40},"apeのアルゴリズムお気持ちベース","APEのアルゴリズム(お気持ちベース)",{"depth":35,"slug":42,"text":43},"提案評価とフィルタリング選択のサイクルを自動化","“提案→評価とフィルタリング→選択”のサイクルを自動化",{"depth":35,"slug":45,"text":45},"指示候補の提案",{"depth":35,"slug":47,"text":48},"評価フィルタリング","評価・フィルタリング",{"depth":50,"slug":51,"text":51},4,"評価基準",{"depth":50,"slug":53,"text":53},"フィルタリング",{"depth":50,"slug":55,"text":55},"選択",{"depth":24,"slug":57,"text":58},"apeを使った結果","APEを使った結果",{"depth":24,"slug":60,"text":60},"いい感じの発見",{"depth":35,"slug":62,"text":63},"zero-shot-chain-of-thought","Zero-shot Chain-of-Thought",{"depth":35,"slug":65,"text":66},"truthfulqa","TruthfulQA",{"depth":24,"slug":68,"text":68},"結論",{"depth":24,"slug":70,"text":70},"感想",[],[],{"title":14,"date":15},[],"Large Language Models Are Human-Level Prompt Engineers(2023).md"]